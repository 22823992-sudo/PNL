{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZAQ4etDXT4P"
      },
      "source": [
        "# Naive Bayes y Pipelines para Clasificación de Texto\n",
        "\n",
        "**Materiales desarrollados por Matías Barreto, 2025**\n",
        "\n",
        "**Tecnicatura en Ciencia de Datos - IFTS**\n",
        "\n",
        "**Asignatura:** Procesamiento de Lenguaje Natural\n",
        "\n",
        "---\n",
        "\n",
        "## Introducción\n",
        "\n",
        "En este notebook vamos a profundizar en dos conceptos fundamentales para el trabajo profesional en Machine Learning:\n",
        "\n",
        "1. **Naive Bayes**: Un algoritmo probabilístico clásico que fue piedra angular en clasificación de texto (spam detection, sentiment analysis) antes de la era del deep learning.\n",
        "\n",
        "2. **Pipelines**: Una forma elegante y profesional de encadenar transformaciones y modelos, facilitando reproducibilidad y despliegue.\n",
        "\n",
        "### Objetivos de aprendizaje\n",
        "\n",
        "1. Comprender el teorema de Bayes y su aplicación en clasificación de texto\n",
        "2. Implementar clasificadores Naive Bayes con sklearn\n",
        "3. Dominar el concepto de Pipeline para flujos de trabajo modulares\n",
        "4. Interpretar métricas avanzadas: precision, recall, F1-score\n",
        "5. Analizar matrices de confusión para detectar patrones de error\n",
        "6. Trabajar con datos en español rioplatense\n",
        "\n",
        "### ¿Por qué es importante este notebook?\n",
        "\n",
        "Los pipelines son el estándar en la industria para organizar código de ML. Además, las métricas que vamos a estudiar (precision, recall, F1) son las mismas que usaremos más adelante para evaluar modelos de transformers en tareas de fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvLi6e7NXT4S"
      },
      "source": [
        "---\n",
        "\n",
        "## 1. Importación de Librerías\n",
        "\n",
        "Importamos las herramientas necesarias, incluyendo componentes para construir pipelines y visualizar resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xCD2ZxqXT4T",
        "outputId": "41926e38-913e-4429-b438-0441f507fced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Librerías importadas correctamente.\n"
          ]
        }
      ],
      "source": [
        "# Librería para manipulación de arrays numéricos\n",
        "import numpy as np\n",
        "\n",
        "# Librería para manipulación de datos tabulares\n",
        "import pandas as pd\n",
        "\n",
        "# Vectorizadores de texto\n",
        "# CountVectorizer: Convierte texto en matriz de conteos (Bag of Words)\n",
        "# TfidfVectorizer: Convierte texto en matriz TF-IDF\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# División de datos y validación cruzada\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "# Pipeline: Encadena múltiples pasos (transformación + modelo)\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Clasificadores\n",
        "# MultinomialNB: Naive Bayes para features discretas (conteos de palabras)\n",
        "# LogisticRegression: Para comparación con el notebook anterior\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Métricas de evaluación\n",
        "# classification_report: Precision, recall, F1-score por clase\n",
        "# confusion_matrix: Matriz de verdaderos/falsos positivos/negativos\n",
        "# ConfusionMatrixDisplay: Visualización gráfica de la matriz\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
        "\n",
        "# Librería para visualización\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Librerías importadas correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IVWjWcWXT4T"
      },
      "source": [
        "---\n",
        "\n",
        "## 2. Dataset en Español Rioplatense\n",
        "\n",
        "A diferencia del notebook anterior (que usó reseñas en inglés), ahora vamos a trabajar con textos en **español rioplatense**. Esto es importante porque:\n",
        "\n",
        "1. Refleja el contexto local argentino\n",
        "2. Introduce vocabulario coloquial (\"quilombo\", \"onda\", \"banda\", \"zafar\")\n",
        "3. Prepara para trabajar con datasets locales en proyectos reales\n",
        "\n",
        "Vamos a crear un pequeño corpus de reseñas de restaurantes y servicios en Buenos Aires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "1yRWyjquXT4U",
        "outputId": "a56c2f29-4ae7-43e0-8dff-59091a30f2d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de reseñas: 20\n",
            "\n",
            "Distribución de clases:\n",
            "etiqueta_texto\n",
            "Positivo    10\n",
            "Negativo    10\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Primeras 5 reseñas:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               texto  sentimiento  \\\n",
              "0  La milanesa a caballo estaba espectacular, muy...            1   \n",
              "1  Qué buena onda la atención, volvería sin dudarlo.            1   \n",
              "2  El flan con dulce de leche es lo más, quedé re...            1   \n",
              "3       Excelente servicio, todo impecable y rápido.            1   \n",
              "4  Me encantó el lugar, súper tranquilo y con bue...            1   \n",
              "\n",
              "  etiqueta_texto  \n",
              "0       Positivo  \n",
              "1       Positivo  \n",
              "2       Positivo  \n",
              "3       Positivo  \n",
              "4       Positivo  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27aaa851-b902-4b91-ab48-d0ad3a18eca3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>etiqueta_texto</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>La milanesa a caballo estaba espectacular, muy...</td>\n",
              "      <td>1</td>\n",
              "      <td>Positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Qué buena onda la atención, volvería sin dudarlo.</td>\n",
              "      <td>1</td>\n",
              "      <td>Positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>El flan con dulce de leche es lo más, quedé re...</td>\n",
              "      <td>1</td>\n",
              "      <td>Positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Excelente servicio, todo impecable y rápido.</td>\n",
              "      <td>1</td>\n",
              "      <td>Positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Me encantó el lugar, súper tranquilo y con bue...</td>\n",
              "      <td>1</td>\n",
              "      <td>Positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27aaa851-b902-4b91-ab48-d0ad3a18eca3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27aaa851-b902-4b91-ab48-d0ad3a18eca3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27aaa851-b902-4b91-ab48-d0ad3a18eca3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-43b86fa5-79e1-4cc2-81c4-f249dd78d407\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43b86fa5-79e1-4cc2-81c4-f249dd78d407')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-43b86fa5-79e1-4cc2-81c4-f249dd78d407 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"texto\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"La milanesa a caballo estaba espectacular, muy recomendable.\",\n          \"Me cobraron de m\\u00e1s y encima se hicieron los giles.\",\n          \"Tardaron dos horas en entregar, lleg\\u00f3 todo fr\\u00edo.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentimiento\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"etiqueta_texto\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Negativo\",\n          \"Positivo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Corpus de reseñas en español rioplatense\n",
        "# Etiqueta: 1 = Positivo, 0 = Negativo\n",
        "textos = [\n",
        "    # Positivas\n",
        "    \"La milanesa a caballo estaba espectacular, muy recomendable.\",\n",
        "    \"Qué buena onda la atención, volvería sin dudarlo.\",\n",
        "    \"El flan con dulce de leche es lo más, quedé re contento.\",\n",
        "    \"Excelente servicio, todo impecable y rápido.\",\n",
        "    \"Me encantó el lugar, súper tranquilo y con buena música.\",\n",
        "    \"La verdad que zafa y está bien de precio.\",\n",
        "    \"Muy copado el ambiente, te sentís como en casa.\",\n",
        "    \"El mejor asado que probé en mucho tiempo, de diez.\",\n",
        "    \"Pedí empanadas y llegaron calentitas, re bien.\",\n",
        "    \"Atención de primera, te explican todo con paciencia.\",\n",
        "\n",
        "    # Negativas\n",
        "    \"El bife de chorizo llegó frío y duro, una decepción.\",\n",
        "    \"Mucho quilombo, tardaron una banda en traer la cuenta.\",\n",
        "    \"La verdad, la pizza dejaba bastante que desear.\",\n",
        "    \"Pésima atención, el mozo tenía mala onda.\",\n",
        "    \"No vuelvo más, carísimo y la comida era un desastre.\",\n",
        "    \"Tardaron dos horas en entregar, llegó todo frío.\",\n",
        "    \"El lugar es un desastre, sucio y con olor raro.\",\n",
        "    \"Me cobraron de más y encima se hicieron los giles.\",\n",
        "    \"La carne estaba pasada, casi no se podía comer.\",\n",
        "    \"Malísima experiencia, no lo recomiendo para nada.\"\n",
        "]\n",
        "\n",
        "# Etiquetas correspondientes (1=positivo, 0=negativo)\n",
        "etiquetas = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  # 10 positivas\n",
        "                      0, 0, 0, 0, 0, 0, 0, 0, 0, 0])  # 10 negativas\n",
        "\n",
        "# Creamos un DataFrame para visualizar mejor\n",
        "df = pd.DataFrame({\n",
        "    'texto': textos,\n",
        "    'sentimiento': etiquetas,\n",
        "    'etiqueta_texto': ['Positivo' if e == 1 else 'Negativo' for e in etiquetas]\n",
        "})\n",
        "\n",
        "print(f\"Total de reseñas: {len(df)}\")\n",
        "print(f\"\\nDistribución de clases:\")\n",
        "print(df['etiqueta_texto'].value_counts())\n",
        "print(f\"\\nPrimeras 5 reseñas:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGjij3cWXT4U"
      },
      "source": [
        "---\n",
        "\n",
        "## 3. División en Conjuntos de Entrenamiento y Prueba\n",
        "\n",
        "Separamos los datos para entrenamiento y evaluación. Con datasets pequeños como este, usamos una proporción 70/30 en lugar de 80/20."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6dlhSSOXT4U",
        "outputId": "f756c00e-384d-41ac-c9ad-e81e955a77e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de entrenamiento: 14 reseñas\n",
            "Conjunto de prueba: 6 reseñas\n",
            "\n",
            "Distribución en entrenamiento: [7 7]\n",
            "Distribución en prueba: [3 3]\n"
          ]
        }
      ],
      "source": [
        "# Separamos características (X) y etiquetas (y)\n",
        "X = df['texto'].values\n",
        "y = df['sentimiento'].values\n",
        "\n",
        "# División 70% entrenamiento, 30% prueba\n",
        "# stratify=y asegura que ambos conjuntos tengan la misma proporción de clases\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.30,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Conjunto de entrenamiento: {len(X_train)} reseñas\")\n",
        "print(f\"Conjunto de prueba: {len(X_test)} reseñas\")\n",
        "print(f\"\\nDistribución en entrenamiento: {np.bincount(y_train)}\")\n",
        "print(f\"Distribución en prueba: {np.bincount(y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UdzbbV7XT4V"
      },
      "source": [
        "---\n",
        "\n",
        "## 4. Naive Bayes: Fundamentos Teóricos\n",
        "\n",
        "### El Teorema de Bayes\n",
        "\n",
        "Naive Bayes se basa en el teorema de Bayes:\n",
        "\n",
        "$$P(clase | documento) = \\frac{P(documento | clase) \\times P(clase)}{P(documento)}$$\n",
        "\n",
        "**Interpretación en nuestro contexto:**\n",
        "- **P(clase | documento)**: Probabilidad de que una reseña sea positiva/negativa dado su texto\n",
        "- **P(documento | clase)**: Probabilidad de observar ese texto en reseñas positivas/negativas\n",
        "- **P(clase)**: Probabilidad a priori de cada clase (frecuencia en el dataset)\n",
        "- **P(documento)**: Probabilidad del documento (constante, se puede ignorar)\n",
        "\n",
        "### La Suposición \"Naive\" (Ingenua)\n",
        "\n",
        "El algoritmo asume **independencia condicional** entre las palabras:\n",
        "\n",
        "$$P(documento | clase) = P(palabra_1 | clase) \\times P(palabra_2 | clase) \\times ... \\times P(palabra_n | clase)$$\n",
        "\n",
        "**¿Por qué es \"naive\"?** Porque en realidad las palabras NO son independientes (\"muy bueno\" tiene más sentido que \"muy\" y \"bueno\" por separado). Sin embargo, en la práctica funciona sorprendentemente bien.\n",
        "\n",
        "### Multinomial Naive Bayes\n",
        "\n",
        "Para clasificación de texto con conteos de palabras, usamos **MultinomialNB**, que modela la distribución multinomial de las palabras en cada clase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOVAKxr4XT4V"
      },
      "source": [
        "---\n",
        "\n",
        "## 5. Entrenamiento Manual (sin Pipeline)\n",
        "\n",
        "Primero entrenamos el modelo de la forma tradicional, paso por paso, para entender el flujo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plASd6JHXT4V",
        "outputId": "be9b4ed8-46fb-4444-f449-6cb920a9efee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de la matriz de entrenamiento: (14, 100)\n",
            "Vocabulario construido con 100 features\n",
            "\n",
            "Modelo Naive Bayes entrenado.\n",
            "\n",
            "Accuracy en el conjunto de prueba: 0.5000 (50.00%)\n"
          ]
        }
      ],
      "source": [
        "# Paso 1: Vectorización\n",
        "# Usamos TF-IDF con unigramas y bigramas\n",
        "# ngram_range=(1,2) captura palabras individuales y pares de palabras\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=100)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Forma de la matriz de entrenamiento: {X_train_vec.shape}\")\n",
        "print(f\"Vocabulario construido con {len(vectorizer.get_feature_names_out())} features\")\n",
        "\n",
        "# Paso 2: Entrenamiento del modelo Naive Bayes\n",
        "# alpha=1.0 es el parámetro de suavizado de Laplace (evita probabilidades cero)\n",
        "clf_nb = MultinomialNB(alpha=1.0)\n",
        "clf_nb.fit(X_train_vec, y_train)\n",
        "\n",
        "print(\"\\nModelo Naive Bayes entrenado.\")\n",
        "\n",
        "# Paso 3: Predicción\n",
        "y_pred = clf_nb.predict(X_test_vec)\n",
        "\n",
        "# Paso 4: Evaluación\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy en el conjunto de prueba: {accuracy:.4f} ({accuracy*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz8w6bgyXT4V"
      },
      "source": [
        "---\n",
        "\n",
        "## 6. Pipelines: La Forma Profesional\n",
        "\n",
        "Los **Pipelines** de sklearn encadenan transformaciones y modelos en un solo objeto. Esto tiene múltiples ventajas:\n",
        "\n",
        "### Ventajas de usar Pipelines\n",
        "\n",
        "1. **Código más limpio**: Todo en un objeto, menos variables temporales\n",
        "2. **Prevención de data leakage**: Garantiza que fit() solo se llame en train\n",
        "3. **Reproducibilidad**: Un objeto contiene todo el flujo\n",
        "4. **Facilita despliegue**: Guardas un solo objeto con pickle/joblib\n",
        "5. **Grid search más simple**: Buscar hiperparámetros de todo el pipeline\n",
        "\n",
        "### Sintaxis de Pipeline\n",
        "\n",
        "```python\n",
        "Pipeline([\n",
        "    ('nombre_paso1', transformador1),\n",
        "    ('nombre_paso2', transformador2),\n",
        "    ('nombre_modelo', modelo)\n",
        "])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_l8SRvgXT4V",
        "outputId": "4b4a14f4-2c00-4041-9a7a-7a0be3553554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline creado:\n",
            "Pipeline(steps=[('tfidf',\n",
            "                 TfidfVectorizer(max_features=100, ngram_range=(1, 2))),\n",
            "                ('clf', MultinomialNB())])\n",
            "\n",
            "Entrenando pipeline...\n",
            "Pipeline entrenado.\n",
            "\n",
            "Accuracy del pipeline: 0.5000 (50.00%)\n"
          ]
        }
      ],
      "source": [
        "# Creamos un Pipeline que encadena TF-IDF + Naive Bayes\n",
        "pipeline_nb = Pipeline([\n",
        "    # Paso 1: Vectorización con TF-IDF\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), max_features=100)),\n",
        "\n",
        "    # Paso 2: Clasificador Naive Bayes\n",
        "    ('clf', MultinomialNB(alpha=1.0))\n",
        "])\n",
        "\n",
        "print(\"Pipeline creado:\")\n",
        "print(pipeline_nb)\n",
        "\n",
        "# Entrenamos el pipeline completo con una sola llamada a fit()\n",
        "# Internamente, hace tfidf.fit_transform() seguido de clf.fit()\n",
        "print(\"\\nEntrenando pipeline...\")\n",
        "pipeline_nb.fit(X_train, y_train)\n",
        "print(\"Pipeline entrenado.\")\n",
        "\n",
        "# Predicción con el pipeline\n",
        "# Internamente, hace tfidf.transform() seguido de clf.predict()\n",
        "y_pred_pipeline = pipeline_nb.predict(X_test)\n",
        "\n",
        "# Evaluación\n",
        "accuracy_pipeline = accuracy_score(y_test, y_pred_pipeline)\n",
        "print(f\"\\nAccuracy del pipeline: {accuracy_pipeline:.4f} ({accuracy_pipeline*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGtncbx9XT4V"
      },
      "source": [
        "### Comparación: Pipeline vs. Forma Manual\n",
        "\n",
        "Veamos la diferencia de código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KILbnNhjXT4W",
        "outputId": "a5fc713b-f006-47a6-8e0b-33933c4322e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "FORMA MANUAL (múltiples pasos)\n",
            "============================================================\n",
            "\n",
            "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
            "X_train_vec = vectorizer.fit_transform(X_train)\n",
            "X_test_vec = vectorizer.transform(X_test)\n",
            "\n",
            "clf = MultinomialNB()\n",
            "clf.fit(X_train_vec, y_train)\n",
            "y_pred = clf.predict(X_test_vec)\n",
            "\n",
            "\n",
            "============================================================\n",
            "FORMA PIPELINE (todo en uno)\n",
            "============================================================\n",
            "\n",
            "pipeline = Pipeline([\n",
            "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
            "    ('clf', MultinomialNB())\n",
            "])\n",
            "\n",
            "pipeline.fit(X_train, y_train)\n",
            "y_pred = pipeline.predict(X_test)\n",
            "\n",
            "\n",
            "¡Mucho más limpio y profesional!\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"FORMA MANUAL (múltiples pasos)\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train_vec, y_train)\n",
        "y_pred = clf.predict(X_test_vec)\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FORMA PIPELINE (todo en uno)\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
        "    ('clf', MultinomialNB())\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n¡Mucho más limpio y profesional!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3vjuI0oXT4W"
      },
      "source": [
        "---\n",
        "\n",
        "## 7. Métricas Avanzadas: Más Allá del Accuracy\n",
        "\n",
        "El accuracy solo nos dice el porcentaje de aciertos totales, pero no nos muestra dónde falla el modelo. Para eso usamos:\n",
        "\n",
        "### Precision (Precisión)\n",
        "$$\\text{Precision} = \\frac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos + Falsos Positivos}}$$\n",
        "\n",
        "**Pregunta que responde:** De todas las reseñas que predijimos como positivas, ¿cuántas lo eran realmente?\n",
        "\n",
        "**Importante cuando:** El costo de falsos positivos es alto (ej: aprobar un spam como legítimo)\n",
        "\n",
        "### Recall (Exhaustividad)\n",
        "$$\\text{Recall} = \\frac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos + Falsos Negativos}}$$\n",
        "\n",
        "**Pregunta que responde:** De todas las reseñas positivas reales, ¿cuántas detectamos?\n",
        "\n",
        "**Importante cuando:** El costo de falsos negativos es alto (ej: detectar fraude)\n",
        "\n",
        "### F1-Score\n",
        "$$\\text{F1} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision + Recall}}$$\n",
        "\n",
        "**Interpretación:** Media armónica entre precision y recall. Útil cuando necesitamos balance entre ambas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCHL8GHCXT4W",
        "outputId": "afdf9015-6f8a-49ba-aff9-dfe28c02f151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "REPORTE DE CLASIFICACIÓN - NAIVE BAYES\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negativo     0.5000    0.3333    0.4000         3\n",
            "    Positivo     0.5000    0.6667    0.5714         3\n",
            "\n",
            "    accuracy                         0.5000         6\n",
            "   macro avg     0.5000    0.5000    0.4857         6\n",
            "weighted avg     0.5000    0.5000    0.4857         6\n",
            "\n",
            "\n",
            "Interpretación de las columnas:\n",
            "------------------------------------------------------------\n",
            "precision: De las predicciones de esa clase, ¿cuántas eran correctas?\n",
            "recall:    De los ejemplos reales de esa clase, ¿cuántos detectamos?\n",
            "f1-score:  Balance entre precision y recall\n",
            "support:   Cantidad de ejemplos de esa clase en el conjunto de prueba\n"
          ]
        }
      ],
      "source": [
        "# Reporte de clasificación completo\n",
        "print(\"=\"*60)\n",
        "print(\"REPORTE DE CLASIFICACIÓN - NAIVE BAYES\")\n",
        "print(\"=\"*60)\n",
        "print(classification_report(y_test, y_pred_pipeline,\n",
        "                          target_names=['Negativo', 'Positivo'],\n",
        "                          digits=4))\n",
        "\n",
        "print(\"\\nInterpretación de las columnas:\")\n",
        "print(\"-\" * 60)\n",
        "print(\"precision: De las predicciones de esa clase, ¿cuántas eran correctas?\")\n",
        "print(\"recall:    De los ejemplos reales de esa clase, ¿cuántos detectamos?\")\n",
        "print(\"f1-score:  Balance entre precision y recall\")\n",
        "print(\"support:   Cantidad de ejemplos de esa clase en el conjunto de prueba\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO9gZQoOXT4W"
      },
      "source": [
        "---\n",
        "\n",
        "## 8. Matriz de Confusión: Visualizando Errores\n",
        "\n",
        "La matriz de confusión muestra en detalle cómo el modelo clasifica cada instancia:\n",
        "\n",
        "```\n",
        "                    Predicho Negativo    Predicho Positivo\n",
        "Real Negativo              TN                   FP\n",
        "Real Positivo              FN                   TP\n",
        "```\n",
        "\n",
        "- **TN (True Negative)**: Negativos correctamente clasificados\n",
        "- **TP (True Positive)**: Positivos correctamente clasificados\n",
        "- **FP (False Positive)**: Negativos clasificados erróneamente como positivos (Error Tipo I)\n",
        "- **FN (False Negative)**: Positivos clasificados erróneamente como negativos (Error Tipo II)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "Uwg6WsFIXT4W",
        "outputId": "3d23240c-5355-441b-f0e1-a74c573f59b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MATRIZ DE CONFUSIÓN\n",
            "============================================================\n",
            "[[1 2]\n",
            " [1 2]]\n",
            "\n",
            "Desglose:\n",
            "Verdaderos Negativos (TN): 1 - Negativos correctamente clasificados\n",
            "Falsos Positivos (FP):     2 - Negativos clasificados como positivos (ERROR)\n",
            "Falsos Negativos (FN):     1 - Positivos clasificados como negativos (ERROR)\n",
            "Verdaderos Positivos (TP): 2 - Positivos correctamente clasificados\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Lectura de la matriz:\n",
            "- La diagonal principal (arriba-izquierda a abajo-derecha) son los ACIERTOS\n",
            "- Los valores fuera de la diagonal son los ERRORES\n",
            "- Idealmente, la diagonal debe ser oscura y el resto claro\n"
          ]
        }
      ],
      "source": [
        "# Calculamos la matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred_pipeline)\n",
        "\n",
        "print(\"MATRIZ DE CONFUSIÓN\")\n",
        "print(\"=\"*60)\n",
        "print(cm)\n",
        "print(\"\\nDesglose:\")\n",
        "print(f\"Verdaderos Negativos (TN): {cm[0,0]} - Negativos correctamente clasificados\")\n",
        "print(f\"Falsos Positivos (FP):     {cm[0,1]} - Negativos clasificados como positivos (ERROR)\")\n",
        "print(f\"Falsos Negativos (FN):     {cm[1,0]} - Positivos clasificados como negativos (ERROR)\")\n",
        "print(f\"Verdaderos Positivos (TP): {cm[1,1]} - Positivos correctamente clasificados\")\n",
        "\n",
        "# Visualización gráfica\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                               display_labels=['Negativo', 'Positivo'])\n",
        "disp.plot(cmap='Blues', ax=ax, values_format='d')\n",
        "plt.title('Matriz de Confusión - Naive Bayes', fontsize=14, pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nLectura de la matriz:\")\n",
        "print(\"- La diagonal principal (arriba-izquierda a abajo-derecha) son los ACIERTOS\")\n",
        "print(\"- Los valores fuera de la diagonal son los ERRORES\")\n",
        "print(\"- Idealmente, la diagonal debe ser oscura y el resto claro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PIlIn3uXT4W"
      },
      "source": [
        "---\n",
        "\n",
        "## 9. Comparación: Naive Bayes vs. Regresión Logística\n",
        "\n",
        "Creamos un segundo pipeline con Regresión Logística para comparar rendimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xncfKXjFXT4W",
        "outputId": "d43b0a33-d7e0-45d7-ad4a-46751f9126d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando pipeline con Regresión Logística...\n",
            "Pipeline entrenado.\n",
            "\n",
            "============================================================\n",
            "COMPARACIÓN DE MODELOS\n",
            "============================================================\n",
            "\n",
            "NAIVE BAYES:\n",
            "------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negativo     0.5000    0.3333    0.4000         3\n",
            "    Positivo     0.5000    0.6667    0.5714         3\n",
            "\n",
            "    accuracy                         0.5000         6\n",
            "   macro avg     0.5000    0.5000    0.4857         6\n",
            "weighted avg     0.5000    0.5000    0.4857         6\n",
            "\n",
            "\n",
            "REGRESIÓN LOGÍSTICA:\n",
            "------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negativo     0.5000    0.3333    0.4000         3\n",
            "    Positivo     0.5000    0.6667    0.5714         3\n",
            "\n",
            "    accuracy                         0.5000         6\n",
            "   macro avg     0.5000    0.5000    0.4857         6\n",
            "weighted avg     0.5000    0.5000    0.4857         6\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Pipeline con Regresión Logística\n",
        "pipeline_lr = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), max_features=100)),\n",
        "    ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
        "])\n",
        "\n",
        "# Entrenamiento\n",
        "print(\"Entrenando pipeline con Regresión Logística...\")\n",
        "pipeline_lr.fit(X_train, y_train)\n",
        "print(\"Pipeline entrenado.\\n\")\n",
        "\n",
        "# Predicciones\n",
        "y_pred_lr = pipeline_lr.predict(X_test)\n",
        "\n",
        "# Comparación de resultados\n",
        "print(\"=\"*60)\n",
        "print(\"COMPARACIÓN DE MODELOS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nNAIVE BAYES:\")\n",
        "print(\"-\" * 60)\n",
        "print(classification_report(y_test, y_pred_pipeline,\n",
        "                          target_names=['Negativo', 'Positivo'],\n",
        "                          digits=4))\n",
        "\n",
        "print(\"\\nREGRESIÓN LOGÍSTICA:\")\n",
        "print(\"-\" * 60)\n",
        "print(classification_report(y_test, y_pred_lr,\n",
        "                          target_names=['Negativo', 'Positivo'],\n",
        "                          digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2agZ2hZXT4W"
      },
      "source": [
        "---\n",
        "\n",
        "## 10. Análisis de Errores: ¿Qué Clasificó Mal el Modelo?\n",
        "\n",
        "Una parte fundamental del trabajo de Data Science es analizar qué casos el modelo clasifica incorrectamente para entender sus limitaciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMFtRGLNXT4W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fcb407a-fc70-4283-ef70-bb9ba09ef7c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ANÁLISIS DE ERRORES\n",
            "================================================================================\n",
            "\n",
            "Total de errores: 3 de 6 (50.0%)\n",
            "\n",
            "Error #1:\n",
            "Texto: \"Pésima atención, el mozo tenía mala onda.\"\n",
            "Etiqueta real: Negativo\n",
            "Predicción: Positivo\n",
            "--------------------------------------------------------------------------------\n",
            "Error #2:\n",
            "Texto: \"El flan con dulce de leche es lo más, quedé re contento.\"\n",
            "Etiqueta real: Positivo\n",
            "Predicción: Negativo\n",
            "--------------------------------------------------------------------------------\n",
            "Error #3:\n",
            "Texto: \"El lugar es un desastre, sucio y con olor raro.\"\n",
            "Etiqueta real: Negativo\n",
            "Predicción: Positivo\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Identificamos las reseñas mal clasificadas\n",
        "errores = X_test[y_test != y_pred_pipeline]\n",
        "etiquetas_reales = y_test[y_test != y_pred_pipeline]\n",
        "etiquetas_predichas = y_pred_pipeline[y_test != y_pred_pipeline]\n",
        "\n",
        "if len(errores) > 0:\n",
        "    print(\"=\"*80)\n",
        "    print(\"ANÁLISIS DE ERRORES\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nTotal de errores: {len(errores)} de {len(X_test)} ({len(errores)/len(X_test)*100:.1f}%)\\n\")\n",
        "\n",
        "    for i, (texto, real, pred) in enumerate(zip(errores, etiquetas_reales, etiquetas_predichas), 1):\n",
        "        real_label = \"Positivo\" if real == 1 else \"Negativo\"\n",
        "        pred_label = \"Positivo\" if pred == 1 else \"Negativo\"\n",
        "\n",
        "        print(f\"Error #{i}:\")\n",
        "        print(f\"Texto: \\\"{texto}\\\"\")\n",
        "        print(f\"Etiqueta real: {real_label}\")\n",
        "        print(f\"Predicción: {pred_label}\")\n",
        "        print(\"-\" * 80)\n",
        "else:\n",
        "    print(\"¡Clasificación perfecta! No hubo errores en el conjunto de prueba.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-aXTznSXT4W"
      },
      "source": [
        "---\n",
        "\n",
        "## 11. Predicciones sobre Textos Nuevos\n",
        "\n",
        "Ahora probamos el modelo con reseñas nuevas que nunca vio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0ib6w2wXT4W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ff5ff1-5144-43b9-838d-dd2b31deac03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "PREDICCIONES SOBRE RESEÑAS NUEVAS\n",
            "================================================================================\n",
            "\n",
            "Reseña: \"La verdad que el lugar está buenísimo, muy recomendable.\"\n",
            "Predicción: POSITIVO\n",
            "Probabilidades: Negativo=35.76%, Positivo=64.24%\n",
            "\n",
            "Reseña: \"Malísimo todo, no vuelvo nunca más.\"\n",
            "Predicción: NEGATIVO\n",
            "Probabilidades: Negativo=56.50%, Positivo=43.50%\n",
            "\n",
            "Reseña: \"Está bien, nada del otro mundo pero safable.\"\n",
            "Predicción: POSITIVO\n",
            "Probabilidades: Negativo=33.76%, Positivo=66.24%\n",
            "\n",
            "Reseña: \"Pedí delivery y llegó todo perfecto, muy contento.\"\n",
            "Predicción: NEGATIVO\n",
            "Probabilidades: Negativo=56.90%, Positivo=43.10%\n",
            "\n",
            "Reseña: \"Una porquería, carísimo y la comida fría.\"\n",
            "Predicción: NEGATIVO\n",
            "Probabilidades: Negativo=58.42%, Positivo=41.58%\n",
            "\n",
            "Reseña: \"Qué buena atención, volvería sin dudarlo.\"\n",
            "Predicción: POSITIVO\n",
            "Probabilidades: Negativo=30.72%, Positivo=69.28%\n"
          ]
        }
      ],
      "source": [
        "# Nuevas reseñas para clasificar\n",
        "nuevas_reseñas = [\n",
        "    \"La verdad que el lugar está buenísimo, muy recomendable.\",\n",
        "    \"Malísimo todo, no vuelvo nunca más.\",\n",
        "    \"Está bien, nada del otro mundo pero safable.\",\n",
        "    \"Pedí delivery y llegó todo perfecto, muy contento.\",\n",
        "    \"Una porquería, carísimo y la comida fría.\",\n",
        "    \"Qué buena atención, volvería sin dudarlo.\"\n",
        "]\n",
        "\n",
        "# Predicciones con el pipeline (automáticamente vectoriza y clasifica)\n",
        "predicciones = pipeline_nb.predict(nuevas_reseñas)\n",
        "\n",
        "# También obtenemos probabilidades\n",
        "probabilidades = pipeline_nb.predict_proba(nuevas_reseñas)\n",
        "\n",
        "# Mostramos resultados\n",
        "print(\"=\"*80)\n",
        "print(\"PREDICCIONES SOBRE RESEÑAS NUEVAS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for i, reseña in enumerate(nuevas_reseñas):\n",
        "    sentimiento = \"POSITIVO\" if predicciones[i] == 1 else \"NEGATIVO\"\n",
        "    prob_neg = probabilidades[i][0] * 100\n",
        "    prob_pos = probabilidades[i][1] * 100\n",
        "\n",
        "    print(f\"\\nReseña: \\\"{reseña}\\\"\")\n",
        "    print(f\"Predicción: {sentimiento}\")\n",
        "    print(f\"Probabilidades: Negativo={prob_neg:.2f}%, Positivo={prob_pos:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-FnrE1JXT4W"
      },
      "source": [
        "---\n",
        "\n",
        "## 12. Validación Cruzada: Evaluación Más Robusta\n",
        "\n",
        "Con datasets pequeños, una sola división train/test puede ser engañosa. La **validación cruzada** (cross-validation) divide los datos en k partes y entrena k veces, usando cada parte como test una vez.\n",
        "\n",
        "### K-Fold Cross-Validation\n",
        "\n",
        "1. Dividir datos en k \"folds\" (pliegues)\n",
        "2. Para cada fold:\n",
        "   - Usar ese fold como test\n",
        "   - Usar los k-1 restantes como train\n",
        "   - Entrenar y evaluar\n",
        "3. Promediar los k resultados\n",
        "\n",
        "Esto da una estimación más estable del rendimiento real del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53QJD831XT4W"
      },
      "outputs": [],
      "source": [
        "# Validación cruzada con 5 folds\n",
        "# cv=5 significa que dividirá los datos en 5 partes\n",
        "print(\"Ejecutando validación cruzada con 5 folds...\\n\")\n",
        "\n",
        "scores_nb = cross_val_score(pipeline_nb, X, y, cv=5, scoring='accuracy')\n",
        "scores_lr = cross_val_score(pipeline_lr, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"RESULTADOS DE VALIDACIÓN CRUZADA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nNAIVE BAYES:\")\n",
        "print(f\"Scores por fold: {scores_nb}\")\n",
        "print(f\"Media: {scores_nb.mean():.4f}\")\n",
        "print(f\"Desviación estándar: {scores_nb.std():.4f}\")\n",
        "\n",
        "print(\"\\nREGRESIÓN LOGÍSTICA:\")\n",
        "print(f\"Scores por fold: {scores_lr}\")\n",
        "print(f\"Media: {scores_lr.mean():.4f}\")\n",
        "print(f\"Desviación estándar: {scores_lr.std():.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Interpretación:\")\n",
        "print(\"-\" * 60)\n",
        "print(\"- La media es el rendimiento esperado del modelo\")\n",
        "print(\"- Una desviación estándar baja indica consistencia\")\n",
        "print(\"- Desviación alta sugiere que el modelo es sensible a la división de datos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYdRm102XT4X"
      },
      "source": [
        "---\n",
        "\n",
        "## Guía Teórico-Conceptual\n",
        "\n",
        "### 1. Naive Bayes: Ventajas y Limitaciones\n",
        "\n",
        "**Ventajas:**\n",
        "- Muy rápido de entrenar y predecir\n",
        "- Requiere poca memoria\n",
        "- Funciona bien con datasets pequeños\n",
        "- Probabilísticamente interpretable\n",
        "- No requiere ajuste de hiperparámetros\n",
        "- Históricamente exitoso en spam detection y sentiment analysis\n",
        "\n",
        "**Limitaciones:**\n",
        "- La suposición de independencia es irreal (palabras están correlacionadas)\n",
        "- No captura orden de palabras ni contexto\n",
        "- Puede ser superado por modelos más sofisticados con suficientes datos\n",
        "- Sensible a features irrelevantes\n",
        "\n",
        "### 2. Pipelines en Producción\n",
        "\n",
        "**Flujo típico en la industria:**\n",
        "\n",
        "```python\n",
        "# 1. Desarrollo\n",
        "pipeline = Pipeline([\n",
        "    ('preprocesamiento', CustomTransformer()),\n",
        "    ('vectorizacion', TfidfVectorizer()),\n",
        "    ('modelo', LogisticRegression())\n",
        "])\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 2. Guardado\n",
        "import joblib\n",
        "joblib.dump(pipeline, 'modelo_produccion.pkl')\n",
        "\n",
        "# 3. Despliegue (en servidor/API)\n",
        "pipeline = joblib.load('modelo_produccion.pkl')\n",
        "prediccion = pipeline.predict([texto_nuevo])\n",
        "```\n",
        "\n",
        "**Ventajas en producción:**\n",
        "- Un solo archivo contiene todo el flujo\n",
        "- No hay riesgo de inconsistencias entre train y producción\n",
        "- Fácil versionado y rollback\n",
        "- Integración simple con APIs (Flask, FastAPI)\n",
        "\n",
        "### 3. Precision vs. Recall: Trade-off\n",
        "\n",
        "**Ejemplo: Detector de spam**\n",
        "\n",
        "**Escenario A: Maximizar Precision**\n",
        "- Solo marcamos como spam cuando estamos MUY seguros\n",
        "- Pocos falsos positivos (emails legítimos marcados como spam)\n",
        "- Pero dejamos pasar más spam (falsos negativos)\n",
        "- Prioridad: No molestar al usuario con clasificaciones erróneas\n",
        "\n",
        "**Escenario B: Maximizar Recall**\n",
        "- Marcamos como spam con menor umbral\n",
        "- Capturamos casi todo el spam (pocos falsos negativos)\n",
        "- Pero más emails legítimos van a spam (falsos positivos)\n",
        "- Prioridad: Limpiar la bandeja de entrada\n",
        "\n",
        "**F1-Score:** Busca el balance óptimo entre ambos\n",
        "\n",
        "### 4. Matriz de Confusión: Interpretación Avanzada\n",
        "\n",
        "**Patrones comunes:**\n",
        "\n",
        "1. **Diagonal dominante:** Buen modelo\n",
        "2. **Columna positiva grande:** Modelo tiende a predecir positivo (bias)\n",
        "3. **Fila positiva grande:** El modelo \"pierde\" muchos positivos reales\n",
        "4. **Matriz simétrica:** Errores balanceados entre clases\n",
        "5. **Matriz asimétrica:** El modelo confunde más una dirección que otra\n",
        "\n",
        "**Aplicación práctica:**\n",
        "- Si FP es alto: El modelo es \"optimista\" (clasifica positivo de más)\n",
        "- Si FN es alto: El modelo es \"pesimista\" (clasifica negativo de más)\n",
        "- Ajustando el umbral de probabilidad podemos mover el trade-off\n",
        "\n",
        "### 5. Validación Cruzada: ¿Cuándo Usarla?\n",
        "\n",
        "**Usar cross-validation cuando:**\n",
        "- Dataset pequeño (< 1000 muestras)\n",
        "- Queremos estimar varianza del modelo\n",
        "- Estamos en fase de selección de modelo\n",
        "- Necesitamos reportar métricas confiables\n",
        "\n",
        "**NO usar cross-validation cuando:**\n",
        "- Dataset muy grande (costoso computacionalmente)\n",
        "- Datos tienen estructura temporal (usar split temporal)\n",
        "- Ya estamos en fase de producción\n",
        "\n",
        "### 6. Suavizado de Laplace en Naive Bayes\n",
        "\n",
        "El parámetro `alpha` en MultinomialNB es el suavizado de Laplace:\n",
        "\n",
        "**Problema:** Si una palabra nunca aparece con una clase en training, su probabilidad es 0, y todo el producto se hace 0.\n",
        "\n",
        "**Solución:** Agregar un pequeño valor (alpha) a todos los conteos:\n",
        "\n",
        "$$P(palabra | clase) = \\frac{count(palabra, clase) + \\alpha}{count(clase) + \\alpha \\times |vocabulario|}$$\n",
        "\n",
        "- `alpha=1.0` (default): Suavizado uniforme\n",
        "- `alpha<1.0`: Menos suavizado (confía más en los datos)\n",
        "- `alpha>1.0`: Más suavizado (más regularización)\n",
        "\n",
        "### 7. N-gramas: Capturando Contexto Local\n",
        "\n",
        "**Unigramas (n=1):** Palabras individuales\n",
        "- Ejemplo: [\"no\", \"me\", \"gusta\"]\n",
        "- Ignora orden completamente\n",
        "\n",
        "**Bigramas (n=2):** Pares de palabras consecutivas\n",
        "- Ejemplo: [\"no me\", \"me gusta\"]\n",
        "- Captura algunas negaciones y frases comunes\n",
        "\n",
        "**Trigramas (n=3):** Tripletas de palabras\n",
        "- Ejemplo: [\"no me gusta\"]\n",
        "- Más contexto pero vocabulario explota (curse of dimensionality)\n",
        "\n",
        "**Trade-off:**\n",
        "- Más n-gramas = más contexto pero más features\n",
        "- Con datasets pequeños, n>2 suele causar overfitting\n",
        "- `ngram_range=(1,2)` es un buen balance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7M5kUwEXT4X"
      },
      "source": [
        "---\n",
        "\n",
        "## Preguntas y Respuestas para Estudio\n",
        "\n",
        "### Preguntas Conceptuales\n",
        "\n",
        "**1. ¿Por qué se llama \"Naive\" (ingenuo) Bayes?**\n",
        "\n",
        "*Respuesta:* Porque asume que todas las palabras son independientes entre sí, lo cual es una suposición simplificadora (naive). En realidad, las palabras están correlacionadas (\"muy bueno\" tiene más sentido que \"muy\" y \"bueno\" por separado), pero esta simplificación hace que el algoritmo sea muy eficiente sin perder demasiada precisión.\n",
        "\n",
        "**2. ¿Cuál es la diferencia entre Multinomial y Gaussian Naive Bayes?**\n",
        "\n",
        "*Respuesta:* MultinomialNB está diseñado para features discretas (conteos de palabras), modelando una distribución multinomial. GaussianNB es para features continuas, asumiendo distribución normal. Para clasificación de texto con BoW/TF-IDF, siempre usamos MultinomialNB.\n",
        "\n",
        "**3. ¿Qué es el suavizado de Laplace y por qué es necesario?**\n",
        "\n",
        "*Respuesta:* Es agregar un pequeño valor (alpha) a todos los conteos para evitar probabilidades cero. Si una palabra nunca apareció con una clase en training, sin suavizado su probabilidad sería 0, haciendo que todo el producto P(documento|clase) sea 0. El suavizado previene este problema.\n",
        "\n",
        "**4. ¿Por qué los pipelines son importantes en la industria?**\n",
        "\n",
        "*Respuesta:* Porque encapsulan todo el flujo (preprocesamiento + modelo) en un objeto serializable. Esto garantiza que el mismo preprocesamiento usado en training se aplique en producción, evita data leakage, facilita versionado y simplifica despliegue. Un error común es usar transformaciones diferentes entre desarrollo y producción.\n",
        "\n",
        "**5. ¿Cuándo preferirías maximizar precision sobre recall?**\n",
        "\n",
        "*Respuesta:* Cuando el costo de falsos positivos es alto. Ejemplos: (1) Sistema de recomendación de cirugías (no queremos recomendar operaciones innecesarias), (2) Detector de spam agresivo (preferimos dejar pasar spam que bloquear emails legítimos), (3) Sistema de préstamos bancarios (mejor rechazar clientes buenos que aprobar morosos).\n",
        "\n",
        "### Preguntas Técnicas\n",
        "\n",
        "**6. ¿Qué información aporta la matriz de confusión que el accuracy no muestra?**\n",
        "\n",
        "*Respuesta:* La matriz muestra dónde falla el modelo: (1) Si confunde más una clase que otra, (2) Si tiene bias hacia predecir cierta clase, (3) La distribución de errores (FP vs FN). Con accuracy solo sabemos el porcentaje total de aciertos, sin visibilidad del comportamiento por clase.\n",
        "\n",
        "**7. En el código del pipeline, ¿por qué usamos fit() en X_train (texto crudo) y no en X_train_vec (vectorizado)?**\n",
        "\n",
        "*Respuesta:* Porque el pipeline encapsula la vectorización. Cuando llamamos `pipeline.fit(X_train, y_train)`, internamente hace: (1) `tfidf.fit_transform(X_train)` para construir vocabulario y vectorizar, (2) `clf.fit(X_train_vec, y_train)` con los datos ya vectorizados. Esto garantiza consistencia.\n",
        "\n",
        "**8. ¿Qué significa que MultinomialNB devuelva probabilidades? ¿Son confiables?**\n",
        "\n",
        "*Respuesta:* `predict_proba()` retorna P(clase|documento) según el teorema de Bayes. Aunque las probabilidades no están perfectamente calibradas (a diferencia de Regresión Logística), son útiles para: (1) Establecer umbrales personalizados, (2) Ordenar predicciones por confianza, (3) Identificar casos ambiguos.\n",
        "\n",
        "**9. ¿Por qué stratify=y en train_test_split?**\n",
        "\n",
        "*Respuesta:* Para mantener la misma proporción de clases en train y test que en el dataset original. Sin stratify, podríamos tener mala suerte y que test tenga 80% de positivos cuando el dataset tiene 50%, sesgando la evaluación. Especialmente importante con datasets pequeños o desbalanceados.\n",
        "\n",
        "**10. ¿Qué pasa si usamos fit() en lugar de transform() en los datos de prueba?**\n",
        "\n",
        "*Respuesta:* Sería un error gravísimo llamado \"data leakage\". El vectorizador aprendería vocabulario de los datos de prueba, \"espiando\" información que el modelo no debería conocer. Esto invalida la evaluación. SIEMPRE: fit() solo en train, transform() en test.\n",
        "\n",
        "### Preguntas de Aplicación\n",
        "\n",
        "**11. Si tuvieras un dataset con 95% clase negativa y 5% positiva, ¿qué ajustes harías?**\n",
        "\n",
        "*Respuesta:*\n",
        "1. NO usar accuracy como métrica principal (un modelo dummy que predice siempre negativo tendría 95% accuracy)\n",
        "2. Usar F1-score, precision y recall para la clase minoritaria\n",
        "3. Considerar técnicas de balanceo: undersampling de mayoritaria, oversampling de minoritaria (SMOTE), o ajustar class_weight en el modelo\n",
        "4. Usar stratified k-fold para garantizar que todos los folds tengan la clase minoritaria\n",
        "\n",
        "**12. ¿En qué casos Naive Bayes podría superar a Regresión Logística?**\n",
        "\n",
        "*Respuesta:*\n",
        "1. Datasets MUY pequeños (< 100 muestras)\n",
        "2. Cuando hay muchas features y pocas muestras (alta dimensionalidad)\n",
        "3. Cuando las suposiciones de Naive Bayes se cumplen razonablemente\n",
        "4. Cuando necesitamos entrenar rapidísimo (NB es más rápido)\n",
        "5. En dominios donde la independencia de features es aproximadamente correcta\n",
        "\n",
        "**13. Describí el flujo completo desde notebook hasta producción usando pipelines.**\n",
        "\n",
        "*Respuesta:*\n",
        "```python\n",
        "# 1. Desarrollo (notebook)\n",
        "pipeline = Pipeline([...])  \n",
        "pipeline.fit(X_train, y_train)\n",
        "evaluar_modelo(pipeline, X_test, y_test)\n",
        "\n",
        "# 2. Serialización\n",
        "import joblib\n",
        "joblib.dump(pipeline, 'modelo_v1.pkl')\n",
        "\n",
        "# 3. API (servidor)\n",
        "from fastapi import FastAPI\n",
        "modelo = joblib.load('modelo_v1.pkl')\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "def predict(texto: str):\n",
        "    pred = modelo.predict([texto])[0]\n",
        "    prob = modelo.predict_proba([texto])[0]\n",
        "    return {\"prediccion\": pred, \"probabilidad\": prob}\n",
        "```\n",
        "\n",
        "**14. ¿Cómo interpretarías una matriz de confusión donde FP >> FN?**\n",
        "\n",
        "*Respuesta:* El modelo es \"optimista\" (clasifica positivo de más). Muchos casos negativos reales son clasificados erróneamente como positivos. Esto indica:\n",
        "- Alta recall para clase positiva (detecta casi todos los positivos)\n",
        "- Baja precision para clase positiva (muchas predicciones positivas son incorrectas)\n",
        "- Posible solución: Aumentar el umbral de probabilidad para clasificar como positivo\n",
        "\n",
        "**15. Si validation accuracy es 90% pero train accuracy es 99%, ¿qué está pasando?**\n",
        "\n",
        "*Respuesta:* **Overfitting**. El modelo memorizó los datos de entrenamiento pero generaliza peor. Soluciones:\n",
        "1. Reducir max_features (vocabulario más pequeño)\n",
        "2. Aumentar regularización (alpha en NB, C en LogReg)\n",
        "3. Usar n-gramas más simples (solo unigramas)\n",
        "4. Conseguir más datos de entrenamiento\n",
        "5. Aplicar técnicas de regularización más agresivas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFeFES19XT4X"
      },
      "source": [
        "---\n",
        "\n",
        "## Ejercicios Propuestos\n",
        "\n",
        "### Ejercicio 1: Experimentación con Alpha\n",
        "Probá valores de alpha en MultinomialNB: 0.1, 0.5, 1.0, 5.0, 10.0. Graficá cómo cambia el accuracy. ¿Cuál es el valor óptimo para este dataset?\n",
        "\n",
        "### Ejercicio 2: Impacto de N-gramas\n",
        "Compará tres configuraciones: (1) solo unigramas, (2) unigramas + bigramas, (3) unigramas + bigramas + trigramas. ¿Cuál da mejor F1-score? ¿Observás overfitting con trigramas?\n",
        "\n",
        "### Ejercicio 3: Dataset Aumentado\n",
        "Agregá 20 reseñas más (10 positivas, 10 negativas) al corpus. Re-entrená y compará métricas. ¿Mejora el modelo?\n",
        "\n",
        "### Ejercicio 4: Pipeline Completo\n",
        "Creá un pipeline que incluya:\n",
        "1. Preprocesamiento personalizado (remover puntuación, lowercase)\n",
        "2. TF-IDF vectorization\n",
        "3. Naive Bayes\n",
        "\n",
        "Pista: Usá `FunctionTransformer` para el preprocesamiento.\n",
        "\n",
        "### Ejercicio 5: Grid Search\n",
        "Usá `GridSearchCV` para buscar los mejores hiperparámetros:\n",
        "- alpha: [0.1, 0.5, 1.0, 2.0]\n",
        "- ngram_range: [(1,1), (1,2), (1,3)]\n",
        "- max_features: [50, 100, 200]\n",
        "\n",
        "¿Qué combinación da el mejor F1-score?\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusión\n",
        "\n",
        "En este notebook profundizamos en dos pilares del Machine Learning aplicado:\n",
        "\n",
        "1. **Naive Bayes**: Un algoritmo probabilístico eficiente y efectivo para clasificación de texto\n",
        "2. **Pipelines**: La forma profesional de organizar flujos de ML para reproducibilidad y despliegue\n",
        "3. **Métricas avanzadas**: Precision, recall, F1-score y matrices de confusión para evaluación rigurosa\n",
        "\n",
        "También trabajamos con datos en **español rioplatense**, relevantes para el contexto local argentino.\n",
        "\n",
        "**Próximo paso:** En el siguiente notebook vamos a implementar un perceptrón desde cero con NumPy para entender los fundamentos de las redes neuronales antes de usar frameworks como PyTorch.\n",
        "\n",
        "---\n",
        "\n",
        "*Este material fue desarrollado con fines educativos para la Tecnicatura en Ciencia de Datos del IFTS.*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}