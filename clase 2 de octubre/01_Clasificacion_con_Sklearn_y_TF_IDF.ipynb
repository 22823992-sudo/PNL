{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl2Uzj9hih3r"
      },
      "source": [
        "# Clasificación de Texto con Scikit-learn y TF-IDF\n",
        "\n",
        "**Materiales desarrollados por Matías Barreto, 2025**\n",
        "\n",
        "**Tecnicatura en Ciencia de Datos - IFTS**\n",
        "\n",
        "**Asignatura:** Procesamiento de Lenguaje Natural\n",
        "\n",
        "---\n",
        "\n",
        "## Introducción\n",
        "\n",
        "En este notebook vas a aprender los fundamentos de la clasificación de texto usando métodos clásicos de Machine Learning. Antes de meternos con redes neuronales, es fundamental establecer un **baseline** (línea de base) que nos permita comparar resultados y entender qué mejoras aportan las arquitecturas más complejas.\n",
        "\n",
        "### Objetivos de aprendizaje\n",
        "\n",
        "1. Comprender el flujo completo de un proyecto de clasificación de texto\n",
        "2. Dominar técnicas de vectorización: **Bag of Words** (BoW) y **TF-IDF**\n",
        "3. Entrenar un modelo de **Regresión Logística** para análisis de sentimiento\n",
        "4. Evaluar el modelo con métricas apropiadas\n",
        "5. Interpretar resultados y hacer predicciones sobre datos nuevos\n",
        "\n",
        "### ¿Qué vamos a construir?\n",
        "\n",
        "Vamos a construir un clasificador de sentimientos que pueda analizar **reseñas de productos en español** y determinar si son **positivas** o **negativas**. Este tipo de sistemas se usan en la industria para análisis de opiniones de clientes, moderación de contenido y detección de tendencias en redes sociales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCwE5RVVih3u"
      },
      "source": [
        "---\n",
        "\n",
        "## 1️⃣ Instalación de Dependencias\n",
        "\n",
        "Instalamos Faker para generar un dataset sintético pero realista en español."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wMisJQIih3u",
        "outputId": "f6b5df1a-f201-4085-d31a-f15fd131d547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m1.8/2.0 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/2.0 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✓ Dependencias instaladas correctamente.\n"
          ]
        }
      ],
      "source": [
        "# Instalación de librerías necesarias\n",
        "# Faker: Para generar datos sintéticos realistas\n",
        "!pip install -q faker\n",
        "\n",
        "print(\"✓ Dependencias instaladas correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkqopKuzih3v"
      },
      "source": [
        "---\n",
        "\n",
        "## 2️⃣ Importación de Librerías\n",
        "\n",
        "Importamos las herramientas necesarias: scikit-learn para ML, pandas para datos, y datasets para cargar el corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdBYUVfpih3w",
        "outputId": "309accd1-e87c-4ec6-b36b-37433f9123f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Librerías importadas correctamente.\n"
          ]
        }
      ],
      "source": [
        "# Librerías para manipulación de datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Vectorización de texto de scikit-learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# División de datos y modelo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Métricas de evaluación\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Para generar datos sintéticos realistas\n",
        "from faker import Faker\n",
        "\n",
        "print(\"✓ Librerías importadas correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_tu_CyGih3w"
      },
      "source": [
        "---\n",
        "\n",
        "## 3️⃣ Generación del Dataset\n",
        "\n",
        "Vamos a crear un dataset **sintético pero realista** de reseñas de productos en español argentino usando técnicas profesionales de generación de datos.\n",
        "\n",
        "Este dataset incluye:\n",
        "- ✅ **Variedad lingüística**: Español rioplatense con expresiones locales\n",
        "- ✅ **Casos complejos**: Ironía, sarcasmo, negaciones\n",
        "- ✅ **Realismo**: Combinaciones naturales de adjetivos y contextos\n",
        "- ✅ **Balance**: Distribución equilibrada de sentimientos\n",
        "\n",
        "### ¿Por qué sintético?\n",
        "\n",
        "Los datasets públicos de reviews en español tienen limitaciones (deprecated, poco balanceados, o en otros dialectos). Un dataset sintético bien diseñado nos permite:\n",
        "\n",
        "1. Controlar el balance de clases\n",
        "2. Incluir casos pedagógicamente útiles (ironía, negaciones)\n",
        "3. Usar español argentino auténtico\n",
        "4. Ajustar el tamaño según necesidad (clase vs TP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGKY0ti_ih3w",
        "outputId": "3797db2c-7774-42af-a94a-9b1fff253245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "DATASET GENERADO\n",
            "======================================================================\n",
            "\n",
            "Total de reseñas: 820\n",
            "\n",
            "Distribución por tipo:\n",
            "tipo\n",
            "ambiguo_negativo      40\n",
            "ambiguo_positivo      40\n",
            "ironia_negativo       80\n",
            "ironia_positivo       80\n",
            "negacion_negativo     40\n",
            "negacion_positivo     40\n",
            "simple_negativo      250\n",
            "simple_positivo      250\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribución de sentimientos:\n",
            "sentiment\n",
            "0    410\n",
            "1    410\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Balance de clases:\n",
            "  Positivas: 50.0%\n",
            "  Negativas: 50.0%\n"
          ]
        }
      ],
      "source": [
        "# Configuramos seeds para reproducibilidad\n",
        "fake = Faker('es_ES')\n",
        "Faker.seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# ============================================================================\n",
        "# TEMPLATES DE RESEÑAS POSITIVAS SIMPLES\n",
        "# ============================================================================\n",
        "\n",
        "# Adjetivos positivos (español rioplatense)\n",
        "adjetivos_positivos = [\n",
        "    \"excelente\", \"genial\", \"buenísimo\", \"espectacular\", \"increíble\",\n",
        "    \"perfecto\", \"maravilloso\", \"bárbaro\", \"copado\", \"grosso\",\n",
        "    \"de primera\", \"impecable\", \"fantástico\", \"hermoso\", \"divino\"\n",
        "]\n",
        "\n",
        "# Verbos positivos\n",
        "verbos_positivos = [\n",
        "    \"me encantó\", \"me fascina\", \"lo recomiendo\", \"superó mis expectativas\",\n",
        "    \"cumple perfectamente\", \"funciona de diez\", \"vale la pena\",\n",
        "    \"estoy re contento\", \"no me arrepiento\", \"la rompe\"\n",
        "]\n",
        "\n",
        "# Contextos positivos\n",
        "contextos_positivos = [\n",
        "    \"Llegó antes de tiempo y en perfecto estado.\",\n",
        "    \"La calidad es superior a lo que esperaba.\",\n",
        "    \"El vendedor fue muy atento y respondió todas mis dudas.\",\n",
        "    \"Por este precio, es una ganga total.\",\n",
        "    \"Mis amigos quedaron fascinados cuando lo vieron.\",\n",
        "    \"Ya es la segunda vez que compro y sigue siendo excelente.\",\n",
        "    \"Lo uso todos los días y sigue como nuevo.\",\n",
        "    \"Mi familia está encantada con la compra.\",\n",
        "]\n",
        "\n",
        "templates_positivos = [\n",
        "    \"{adj} producto, {verbo}. {contexto}\",\n",
        "    \"{verbo}, {adj} compra. {contexto}\",\n",
        "    \"El producto es {adj}. {contexto} {verbo}.\",\n",
        "    \"{contexto} Realmente {adj}, {verbo}.\",\n",
        "    \"{adj} en todo sentido. {verbo}. {contexto}\",\n",
        "]\n",
        "\n",
        "# ============================================================================\n",
        "# TEMPLATES DE RESEÑAS NEGATIVAS SIMPLES\n",
        "# ============================================================================\n",
        "\n",
        "# Adjetivos negativos (español rioplatense)\n",
        "adjetivos_negativos = [\n",
        "    \"horrible\", \"malísimo\", \"pésimo\", \"terrible\", \"espantoso\",\n",
        "    \"desastroso\", \"deplorable\", \"trucho\", \"berreta\", \"choto\",\n",
        "    \"un desastre\", \"una porquería\", \"un fiasco\", \"decepcionante\", \"lamentable\"\n",
        "]\n",
        "\n",
        "# Verbos negativos\n",
        "verbos_negativos = [\n",
        "    \"no lo recomiendo\", \"me arrepiento de comprarlo\", \"pérdida de plata\",\n",
        "    \"tuve que devolverlo\", \"no funciona\", \"se rompió enseguida\",\n",
        "    \"no vale la pena\", \"es una estafa\", \"no cumple lo prometido\",\n",
        "    \"quedé re decepcionado\"\n",
        "]\n",
        "\n",
        "# Contextos negativos\n",
        "contextos_negativos = [\n",
        "    \"Se rompió a los pocos días de uso.\",\n",
        "    \"La calidad es muy inferior a la descripción.\",\n",
        "    \"El vendedor no responde los mensajes.\",\n",
        "    \"Tardó más de un mes en llegar.\",\n",
        "    \"Llegó todo golpeado y con partes faltantes.\",\n",
        "    \"No se parece en nada a las fotos.\",\n",
        "    \"Hace ruidos extraños y se sobrecalienta.\",\n",
        "    \"El material es plástico barato de mala calidad.\",\n",
        "]\n",
        "\n",
        "templates_negativos = [\n",
        "    \"{adj} producto, {verbo}. {contexto}\",\n",
        "    \"{verbo}, {adj} experiencia. {contexto}\",\n",
        "    \"El producto es {adj}. {contexto} {verbo}.\",\n",
        "    \"{contexto} Realmente {adj}, {verbo}.\",\n",
        "    \"{adj} en todo sentido. {verbo}. {contexto}\",\n",
        "]\n",
        "\n",
        "# ============================================================================\n",
        "# CASOS DIFÍCILES: IRONÍA Y SARCASMO (Sin señales obvias)\n",
        "# ============================================================================\n",
        "\n",
        "# IRONÍA POSITIVA: Empieza mal pero termina bien (señal confusa al principio)\n",
        "casos_ironia_positiva = [\n",
        "    \"Pensé que iba a ser horrible, pero me equivoqué completamente.\",\n",
        "    \"Las primeras impresiones eran malas, terminó siendo muy útil.\",\n",
        "    \"No confiaba en este producto, ahora lo uso todos los días.\",\n",
        "    \"Dudaba mucho, pero resultó ser mejor que productos más caros.\",\n",
        "    \"Parecía trucho, funciona mejor que otras marcas conocidas.\",\n",
        "    \"Tenía miedo de que fuera malo, pero fue una grata sorpresa.\",\n",
        "    \"Creí que me iban a estafar, resultó ser confiable.\",\n",
        "    \"Me arrepentía de comprarlo, ahora pienso que fue buena idea.\",\n",
        "    \"Al principio desconfié, terminó superando expectativas.\",\n",
        "    \"Venía con dudas, resultó mejor de lo imaginado.\",\n",
        "]\n",
        "\n",
        "# IRONÍA NEGATIVA SUTIL: Sarcasmo sin palabras negativas explícitas\n",
        "# Estos son genuinamente difíciles porque solo tienen palabras positivas\n",
        "casos_ironia_negativa = [\n",
        "    \"Claro, porque yo tengo plata para tirar. Súper recomendable.\",\n",
        "    \"Hermoso, justo lo que necesitaba para decorar la basura.\",\n",
        "    \"Fantástico, ahora tengo un pisapapeles muy caro.\",\n",
        "    \"Perfecto, me encanta cuando las cosas duran una semana.\",\n",
        "    \"Genial, ideal para regalarle a alguien que no te cae bien.\",\n",
        "    \"Excelente, porque a quién no le gusta perder el tiempo.\",\n",
        "    \"Maravilloso, especialmente si disfrutás de las decepciones.\",\n",
        "    \"Divino, lo mejor para aprender a no confiar en las reviews.\",\n",
        "    \"Espectacular, perfecto para quienes aman tirar dinero.\",\n",
        "    \"Increíble, nunca había visto algo tan inútil por tanto dinero.\",\n",
        "]\n",
        "\n",
        "# NEGACIÓN POSITIVA - Más variedad de patrones\n",
        "casos_negacion_positiva = [\n",
        "    \"No tengo quejas, cumple perfectamente su función.\",\n",
        "    \"Jamás tuve problemas, funciona muy bien.\",\n",
        "    \"No me arrepiento, fue buena compra.\",\n",
        "    \"No esperaba tanto, superó lo que imaginaba.\",\n",
        "    \"Para nada malo, al contrario, bastante bueno.\",\n",
        "    \"Sin ningún defecto que mencionar, todo correcto.\",\n",
        "    \"No encuentro fallas, todo funciona perfecto.\",\n",
        "    \"Nunca me falló, siempre anda bien.\",\n",
        "]\n",
        "\n",
        "# NEGACIÓN NEGATIVA - Patrones variados\n",
        "casos_negacion_negativa = [\n",
        "    \"No funciona, no sirve, no lo compren.\",\n",
        "    \"Jamás vuelvo a comprar esto, mala experiencia.\",\n",
        "    \"No lo recomiendo, tuve muchos problemas.\",\n",
        "    \"Para nada lo que esperaba, muy decepcionante.\",\n",
        "    \"Sin dudas la peor compra, no vale la pena.\",\n",
        "    \"No cumple lo prometido, perdí plata.\",\n",
        "    \"Nunca anduvo bien, siempre con fallas.\",\n",
        "    \"Ni funciona ni vale lo que cuesta.\",\n",
        "]\n",
        "\n",
        "# CASOS VERDADERAMENTE AMBIGUOS - Equilibrio perfecto de positivo/negativo\n",
        "# Estos deberían confundir al modelo porque tienen IGUAL cantidad de señales\n",
        "casos_ambiguos_positivos = [\n",
        "    \"Tiene defectos, pero en general funciona bien.\",\n",
        "    \"No es perfecto, aunque cumple lo esperado.\",\n",
        "    \"Algunos aspectos mejorables, pero satisfecho con la compra.\",\n",
        "    \"Podría ser mejor, igual lo uso sin problemas.\",\n",
        "    \"Esperaba más calidad, pero el precio compensa.\",\n",
        "    \"Fallos menores, en conjunto buena experiencia.\",\n",
        "    \"Ciertos detalles negativos, aún así lo recomiendo.\",\n",
        "]\n",
        "\n",
        "casos_ambiguos_negativos = [\n",
        "    \"Funciona bien, pero no justifica el precio alto.\",\n",
        "    \"Lindo diseño, lástima que no sirve.\",\n",
        "    \"Cumple lo básico, pero esperaba algo superior.\",\n",
        "    \"Buena presentación, terrible calidad interna.\",\n",
        "    \"Lo positivo no alcanza para compensar los problemas.\",\n",
        "    \"Algunos aspectos buenos, pero demasiados defectos.\",\n",
        "    \"Precio razonable, rendimiento inaceptable.\",\n",
        "]\n",
        "\n",
        "# ============================================================================\n",
        "# GENERACIÓN DEL DATASET\n",
        "# ============================================================================\n",
        "\n",
        "def generar_review_positiva():\n",
        "    \"\"\"Genera una reseña positiva realista\"\"\"\n",
        "    template = random.choice(templates_positivos)\n",
        "    adj = random.choice(adjetivos_positivos)\n",
        "    verbo = random.choice(verbos_positivos)\n",
        "    contexto = random.choice(contextos_positivos)\n",
        "\n",
        "    return template.format(adj=adj, verbo=verbo, contexto=contexto)\n",
        "\n",
        "def generar_review_negativa():\n",
        "    \"\"\"Genera una reseña negativa realista\"\"\"\n",
        "    template = random.choice(templates_negativos)\n",
        "    adj = random.choice(adjetivos_negativos)\n",
        "    verbo = random.choice(verbos_negativos)\n",
        "    contexto = random.choice(contextos_negativos)\n",
        "\n",
        "    return template.format(adj=adj, verbo=verbo, contexto=contexto)\n",
        "\n",
        "# Configuración del dataset: reducimos casos simples y aumentamos difíciles\n",
        "n_simples_por_clase = 250  # Reviews simples (reducido para dar más peso a casos difíciles)\n",
        "n_casos_especiales = 80    # Casos difíciles (aumentado significativamente)\n",
        "\n",
        "reviews = []\n",
        "sentiments = []\n",
        "tipos = []\n",
        "\n",
        "# 1. Reviews positivas simples\n",
        "for _ in range(n_simples_por_clase):\n",
        "    reviews.append(generar_review_positiva())\n",
        "    sentiments.append(1)\n",
        "    tipos.append('simple_positivo')\n",
        "\n",
        "# 2. Reviews negativas simples\n",
        "for _ in range(n_simples_por_clase):\n",
        "    reviews.append(generar_review_negativa())\n",
        "    sentiments.append(0)\n",
        "    tipos.append('simple_negativo')\n",
        "\n",
        "# 3. Ironía positiva (empieza negativo, termina positivo)\n",
        "for _ in range(n_casos_especiales):\n",
        "    caso = random.choice(casos_ironia_positiva)\n",
        "    reviews.append(caso)\n",
        "    sentiments.append(1)\n",
        "    tipos.append('ironia_positivo')\n",
        "\n",
        "# 4. Ironía negativa (sarcasmo - usa palabras positivas pero es negativo)\n",
        "for _ in range(n_casos_especiales):\n",
        "    caso = random.choice(casos_ironia_negativa)\n",
        "    reviews.append(caso)\n",
        "    sentiments.append(0)\n",
        "    tipos.append('ironia_negativo')\n",
        "\n",
        "# 5. Negación positiva\n",
        "for _ in range(n_casos_especiales // 2):\n",
        "    caso = random.choice(casos_negacion_positiva)\n",
        "    reviews.append(caso)\n",
        "    sentiments.append(1)\n",
        "    tipos.append('negacion_positivo')\n",
        "\n",
        "# 6. Negación negativa\n",
        "for _ in range(n_casos_especiales // 2):\n",
        "    caso = random.choice(casos_negacion_negativa)\n",
        "    reviews.append(caso)\n",
        "    sentiments.append(0)\n",
        "    tipos.append('negacion_negativo')\n",
        "\n",
        "# 7. Casos ambiguos positivos\n",
        "for _ in range(n_casos_especiales // 2):\n",
        "    caso = random.choice(casos_ambiguos_positivos)\n",
        "    reviews.append(caso)\n",
        "    sentiments.append(1)\n",
        "    tipos.append('ambiguo_positivo')\n",
        "\n",
        "# 8. Casos ambiguos negativos\n",
        "for _ in range(n_casos_especiales // 2):\n",
        "    caso = random.choice(casos_ambiguos_negativos)\n",
        "    reviews.append(caso)\n",
        "    sentiments.append(0)\n",
        "    tipos.append('ambiguo_negativo')\n",
        "\n",
        "# Creamos DataFrame\n",
        "df_full = pd.DataFrame({\n",
        "    'review_body': reviews,\n",
        "    'sentiment': sentiments,\n",
        "    'tipo': tipos,\n",
        "    'stars': [5 if s == 1 else 1 for s in sentiments],\n",
        "    'review_title': [''] * len(reviews)\n",
        "})\n",
        "\n",
        "# Mezclamos aleatoriamente\n",
        "df_full = df_full.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DATASET GENERADO\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nTotal de reseñas: {len(df_full):,}\")\n",
        "print(f\"\\nDistribución por tipo:\")\n",
        "print(df_full['tipo'].value_counts().sort_index())\n",
        "print(f\"\\nDistribución de sentimientos:\")\n",
        "print(df_full['sentiment'].value_counts())\n",
        "print(f\"\\nBalance de clases:\")\n",
        "print(f\"  Positivas: {(df_full['sentiment']==1).sum()/len(df_full)*100:.1f}%\")\n",
        "print(f\"  Negativas: {(df_full['sentiment']==0).sum()/len(df_full)*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLJWN5Ldih3x"
      },
      "source": [
        "### Análisis del dataset generado\n",
        "\n",
        "Veamos la distribución de tipos de reseñas y algunos ejemplos de cada categoría."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHNDbmGDih3x",
        "outputId": "9218fdd7-aeaa-4c1a-86f4-55a06a7f78a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "EJEMPLOS DE RESEÑAS POR CATEGORÍA\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "TIPO: AMBIGUO_NEGATIVO\n",
            "================================================================================\n",
            "\n",
            "  [NEGATIVO ✗] Precio razonable, rendimiento inaceptable.\n",
            "\n",
            "  [NEGATIVO ✗] Lindo diseño, lástima que no sirve.\n",
            "\n",
            "  [NEGATIVO ✗] Algunos aspectos buenos, pero demasiados defectos.\n",
            "\n",
            "================================================================================\n",
            "TIPO: AMBIGUO_POSITIVO\n",
            "================================================================================\n",
            "\n",
            "  [POSITIVO ✓] No es perfecto, aunque cumple lo esperado.\n",
            "\n",
            "  [POSITIVO ✓] Ciertos detalles negativos, aún así lo recomiendo.\n",
            "\n",
            "  [POSITIVO ✓] Fallos menores, en conjunto buena experiencia.\n",
            "\n",
            "================================================================================\n",
            "TIPO: IRONIA_NEGATIVO\n",
            "================================================================================\n",
            "\n",
            "  [NEGATIVO ✗] Claro, porque yo tengo plata para tirar. Súper recomendable.\n",
            "\n",
            "  [NEGATIVO ✗] Claro, porque yo tengo plata para tirar. Súper recomendable.\n",
            "\n",
            "  [NEGATIVO ✗] Fantástico, ahora tengo un pisapapeles muy caro.\n",
            "\n",
            "================================================================================\n",
            "TIPO: IRONIA_POSITIVO\n",
            "================================================================================\n",
            "\n",
            "  [POSITIVO ✓] Venía con dudas, resultó mejor de lo imaginado.\n",
            "\n",
            "  [POSITIVO ✓] Las primeras impresiones eran malas, terminó siendo muy útil.\n",
            "\n",
            "  [POSITIVO ✓] Venía con dudas, resultó mejor de lo imaginado.\n",
            "\n",
            "================================================================================\n",
            "TIPO: NEGACION_NEGATIVO\n",
            "================================================================================\n",
            "\n",
            "  [NEGATIVO ✗] Para nada lo que esperaba, muy decepcionante.\n",
            "\n",
            "  [NEGATIVO ✗] Ni funciona ni vale lo que cuesta.\n",
            "\n",
            "  [NEGATIVO ✗] Para nada lo que esperaba, muy decepcionante.\n",
            "\n",
            "================================================================================\n",
            "TIPO: NEGACION_POSITIVO\n",
            "================================================================================\n",
            "\n",
            "  [POSITIVO ✓] No tengo quejas, cumple perfectamente su función.\n",
            "\n",
            "  [POSITIVO ✓] No me arrepiento, fue buena compra.\n",
            "\n",
            "  [POSITIVO ✓] Nunca me falló, siempre anda bien.\n",
            "\n",
            "================================================================================\n",
            "TIPO: SIMPLE_NEGATIVO\n",
            "================================================================================\n",
            "\n",
            "  [NEGATIVO ✗] pésimo en todo sentido. no vale la pena. El material es plástico barato de mala calidad.\n",
            "\n",
            "  [NEGATIVO ✗] choto en todo sentido. tuve que devolverlo. El vendedor no responde los mensajes.\n",
            "\n",
            "  [NEGATIVO ✗] quedé re decepcionado, decepcionante experiencia. El vendedor no responde los mensajes.\n",
            "\n",
            "================================================================================\n",
            "TIPO: SIMPLE_POSITIVO\n",
            "================================================================================\n",
            "\n",
            "  [POSITIVO ✓] no me arrepiento, impecable compra. Mis amigos quedaron fascinados cuando lo vieron.\n",
            "\n",
            "  [POSITIVO ✓] lo recomiendo, perfecto compra. Mis amigos quedaron fascinados cuando lo vieron.\n",
            "\n",
            "  [POSITIVO ✓] El producto es genial. El vendedor fue muy atento y respondió todas mis dudas. me fascina.\n",
            "\n",
            "================================================================================\n",
            "💡 NOTA PEDAGÓGICA:\n",
            "================================================================================\n",
            "Los casos de 'ironía' y 'negación' son DESAFIANTES para el modelo.\n",
            "Observá cómo palabras positivas pueden expresar sentimiento negativo\n",
            "(y viceversa) según el contexto. ¡Esto es clave para entender las\n",
            "limitaciones de BoW/TF-IDF y motivar el uso de modelos más avanzados!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Trabajamos con el dataset completo\n",
        "df = df_full.copy()\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"EJEMPLOS DE RESEÑAS POR CATEGORÍA\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Mostramos ejemplos de cada tipo\n",
        "tipos_unicos = df['tipo'].unique()\n",
        "\n",
        "for tipo in sorted(tipos_unicos):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TIPO: {tipo.upper()}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Mostramos 3 ejemplos de este tipo\n",
        "    ejemplos = df[df['tipo'] == tipo].sample(min(3, len(df[df['tipo'] == tipo])), random_state=42)\n",
        "\n",
        "    for idx, row in ejemplos.iterrows():\n",
        "        sentiment_label = \"POSITIVO ✓\" if row['sentiment'] == 1 else \"NEGATIVO ✗\"\n",
        "        print(f\"\\n  [{sentiment_label}] {row['review_body']}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"💡 NOTA PEDAGÓGICA:\")\n",
        "print(\"=\"*80)\n",
        "print(\"Los casos de 'ironía' y 'negación' son DESAFIANTES para el modelo.\")\n",
        "print(\"Observá cómo palabras positivas pueden expresar sentimiento negativo\")\n",
        "print(\"(y viceversa) según el contexto. ¡Esto es clave para entender las\")\n",
        "print(\"limitaciones de BoW/TF-IDF y motivar el uso de modelos más avanzados!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7HTIa6lih3x"
      },
      "source": [
        "### Ejemplos específicos para la clase\n",
        "\n",
        "Veamos algunas reseñas positivas y negativas para entender nuestros datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab0uW1glih3x",
        "outputId": "9bfbaa39-eb66-472f-b70b-2251f25a4766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "RESEÑAS POSITIVAS (SIMPLES)\n",
            "================================================================================\n",
            "\n",
            "★★★★★ El vendedor fue muy atento y respondió todas mis dudas. Realmente divino, me encantó.\n",
            "\n",
            "★★★★★ grosso en todo sentido. la rompe. Por este precio, es una ganga total.\n",
            "\n",
            "★★★★★ Mis amigos quedaron fascinados cuando lo vieron. Realmente hermoso, no me arrepiento.\n",
            "\n",
            "★★★★★ genial en todo sentido. vale la pena. Lo uso todos los días y sigue como nuevo.\n",
            "\n",
            "★★★★★ perfecto en todo sentido. estoy re contento. Llegó antes de tiempo y en perfecto estado.\n",
            "\n",
            "================================================================================\n",
            "RESEÑAS NEGATIVAS (SIMPLES)\n",
            "================================================================================\n",
            "\n",
            "★☆☆☆☆ La calidad es muy inferior a la descripción. Realmente trucho, se rompió enseguida.\n",
            "\n",
            "★☆☆☆☆ desastroso producto, no funciona. La calidad es muy inferior a la descripción.\n",
            "\n",
            "★☆☆☆☆ El producto es malísimo. Llegó todo golpeado y con partes faltantes. pérdida de plata.\n",
            "\n",
            "★☆☆☆☆ lamentable en todo sentido. me arrepiento de comprarlo. La calidad es muy inferior a la descripción.\n",
            "\n",
            "★☆☆☆☆ Se rompió a los pocos días de uso. Realmente espantoso, no lo recomiendo.\n",
            "\n",
            "================================================================================\n",
            "CASOS DESAFIANTES (Ironía/Sarcasmo)\n",
            "================================================================================\n",
            "\n",
            "🔥 IRONÍA NEGATIVA (dice 'excelente' pero es NEGATIVO):\n",
            "  ✗ Claro, porque yo tengo plata para tirar. Súper recomendable.\n",
            "  ✗ Hermoso, justo lo que necesitaba para decorar la basura.\n",
            "  ✗ Fantástico, ahora tengo un pisapapeles muy caro.\n",
            "\n",
            "🔥 NEGACIONES COMPLEJAS:\n",
            "  ✓ No tengo quejas, cumple perfectamente su función.\n",
            "  ✗ No funciona, no sirve, no lo compren.\n"
          ]
        }
      ],
      "source": [
        "# Ejemplos de reseñas positivas simples\n",
        "print(\"=\" * 80)\n",
        "print(\"RESEÑAS POSITIVAS (SIMPLES)\")\n",
        "print(\"=\" * 80)\n",
        "for i, row in df[df['tipo'] == 'simple_positivo'].head(5).iterrows():\n",
        "    print(f\"\\n★★★★★ {row['review_body']}\")\n",
        "\n",
        "# Ejemplos de reseñas negativas simples\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"RESEÑAS NEGATIVAS (SIMPLES)\")\n",
        "print(\"=\" * 80)\n",
        "for i, row in df[df['tipo'] == 'simple_negativo'].head(5).iterrows():\n",
        "    print(f\"\\n★☆☆☆☆ {row['review_body']}\")\n",
        "\n",
        "# Casos especiales que el modelo puede fallar\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"CASOS DESAFIANTES (Ironía/Sarcasmo)\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\n🔥 IRONÍA NEGATIVA (dice 'excelente' pero es NEGATIVO):\")\n",
        "for caso in casos_ironia_negativa[:3]:\n",
        "    print(f\"  ✗ {caso}\")\n",
        "\n",
        "print(\"\\n🔥 NEGACIONES COMPLEJAS:\")\n",
        "print(f\"  ✓ {casos_negacion_positiva[0]}\")\n",
        "print(f\"  ✗ {casos_negacion_negativa[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3Y3h2SYih3x"
      },
      "source": [
        "---\n",
        "\n",
        "## 4️⃣ División en Conjuntos de Entrenamiento y Prueba\n",
        "\n",
        "Un principio fundamental en Machine Learning es **nunca evaluar el modelo con los mismos datos que usamos para entrenarlo**. Si lo hacemos, el modelo podría simplemente memorizar los datos (overfitting) y no generalizar bien a datos nuevos.\n",
        "\n",
        "Por eso dividimos el dataset en dos conjuntos:\n",
        "- **Entrenamiento (80%)**: Para que el modelo aprenda patrones\n",
        "- **Prueba (20%)**: Para evaluar el rendimiento en datos no vistos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GKcZeo6ih3x",
        "outputId": "960b55db-b2c3-47fa-b4a6-fa4b75d1b10c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento: 656 reseñas\n",
            "Tamaño del conjunto de prueba: 164 reseñas\n",
            "\n",
            "Distribución en entrenamiento:\n",
            "  Positivas: 328 (50.0%)\n",
            "  Negativas: 328 (50.0%)\n"
          ]
        }
      ],
      "source": [
        "# Separamos características (X) de etiquetas (y)\n",
        "# Usamos 'review_body' que contiene el texto completo de la reseña\n",
        "reviews = df['review_body'].values\n",
        "sentiments = df['sentiment'].values\n",
        "\n",
        "# train_test_split divide aleatoriamente los datos\n",
        "# test_size=0.2 → 20% prueba, 80% entrenamiento\n",
        "# stratify=sentiments → mantiene proporción de clases en ambos conjuntos\n",
        "reviews_train, reviews_test, sentiment_train, sentiment_test = train_test_split(\n",
        "    reviews,\n",
        "    sentiments,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=sentiments\n",
        ")\n",
        "\n",
        "print(f\"Tamaño del conjunto de entrenamiento: {len(reviews_train):,} reseñas\")\n",
        "print(f\"Tamaño del conjunto de prueba: {len(reviews_test):,} reseñas\")\n",
        "print(f\"\\nDistribución en entrenamiento:\")\n",
        "print(f\"  Positivas: {sum(sentiment_train==1):,} ({sum(sentiment_train==1)/len(sentiment_train)*100:.1f}%)\")\n",
        "print(f\"  Negativas: {sum(sentiment_train==0):,} ({sum(sentiment_train==0)/len(sentiment_train)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCLcR7kwih3y"
      },
      "source": [
        "---\n",
        "\n",
        "## 5️⃣ Vectorización de Texto: De Palabras a Números\n",
        "\n",
        "Los algoritmos de Machine Learning trabajan con números, no con texto. Necesitamos convertir las reseñas en vectores numéricos. Vamos a explorar dos técnicas:\n",
        "\n",
        "### 5.1. Bag of Words (BoW) con CountVectorizer\n",
        "\n",
        "Esta técnica representa cada documento como un vector de conteos de palabras. Ignora el orden pero captura la frecuencia.\n",
        "\n",
        "**Ejemplo:**\n",
        "```\n",
        "Texto 1: \"Me gusta el producto\"\n",
        "Texto 2: \"No me gusta nada\"\n",
        "\n",
        "Vocabulario: [\"me\", \"gusta\", \"el\", \"producto\", \"no\", \"nada\"]\n",
        "\n",
        "Vector Texto 1: [1, 1, 1, 1, 0, 0]  # Conteo de cada palabra\n",
        "Vector Texto 2: [1, 1, 0, 0, 1, 1]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih_Hv4tbih3y",
        "outputId": "a00cb796-4c35-47c8-f69c-f4cae9244375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de la matriz de entrenamiento: (656, 296)\n",
            "Esto significa: 656 documentos × 296 palabras\n",
            "\n",
            "Primeras 10 palabras del vocabulario: ['ahora', 'al', 'alcanza', 'algo', 'alguien', 'algunos', 'alto', 'aman', 'amigos', 'anda']\n"
          ]
        }
      ],
      "source": [
        "# Creamos el vectorizador CountVectorizer\n",
        "# max_features=1000 limita el vocabulario a las 1000 palabras más frecuentes\n",
        "count_vectorizer = CountVectorizer(max_features=1000)\n",
        "\n",
        "# fit() construye el vocabulario desde los datos de entrenamiento\n",
        "# transform() convierte textos en matrices de conteos\n",
        "X_train_counts = count_vectorizer.fit_transform(reviews_train)\n",
        "X_test_counts = count_vectorizer.transform(reviews_test)\n",
        "\n",
        "print(f\"Forma de la matriz de entrenamiento: {X_train_counts.shape}\")\n",
        "print(f\"Esto significa: {X_train_counts.shape[0]} documentos × {X_train_counts.shape[1]} palabras\")\n",
        "print(f\"\\nPrimeras 10 palabras del vocabulario: {list(count_vectorizer.get_feature_names_out()[:10])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaZ4tzJ7ih3y"
      },
      "source": [
        "### 5.2. TF-IDF (Term Frequency - Inverse Document Frequency)\n",
        "\n",
        "TF-IDF mejora BoW al ponderar las palabras según su importancia:\n",
        "- **TF (Term Frequency)**: Qué tan frecuente es una palabra en un documento\n",
        "- **IDF (Inverse Document Frequency)**: Qué tan rara es esa palabra en todo el corpus\n",
        "\n",
        "**Intuición:** Palabras como \"el\", \"de\", \"la\" aparecen en casi todos los documentos, por lo que tienen poco valor discriminativo. TF-IDF les asigna pesos bajos. Palabras específicas como \"excelente\" o \"horrible\" tienen pesos altos.\n",
        "\n",
        "**Fórmula:**\n",
        "```\n",
        "TF-IDF(palabra, documento) = TF(palabra, documento) × IDF(palabra)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTnwUdsmih3y",
        "outputId": "ffe783d6-2aef-46d9-c9f0-26bb4ac99d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de la matriz TF-IDF: (656, 296)\n",
            "Tipo de matriz: <class 'scipy.sparse._csr.csr_matrix'> (sparse matrix para ahorrar memoria)\n"
          ]
        }
      ],
      "source": [
        "# Creamos el vectorizador TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "# fit_transform() combina fit() + transform()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(reviews_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(reviews_test)\n",
        "\n",
        "print(f\"Forma de la matriz TF-IDF: {X_train_tfidf.shape}\")\n",
        "print(f\"Tipo de matriz: {type(X_train_tfidf)} (sparse matrix para ahorrar memoria)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8bWMPLzih3y"
      },
      "source": [
        "---\n",
        "\n",
        "## 6️⃣ Entrenamiento del Modelo: Regresión Logística\n",
        "\n",
        "Vamos a entrenar dos modelos (uno con BoW y otro con TF-IDF) y comparar su rendimiento.\n",
        "\n",
        "### ¿Por qué Regresión Logística?\n",
        "\n",
        "Aunque el nombre dice \"regresión\", es un algoritmo de **clasificación**. Es simple, rápido, interpretable y funciona sorprendentemente bien como baseline para clasificación de texto.\n",
        "\n",
        "**Ventajas:**\n",
        "- Rápido de entrenar\n",
        "- Requiere poca memoria\n",
        "- Produce probabilidades calibradas\n",
        "- Los pesos del modelo son interpretables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrVWd2Dnih3y",
        "outputId": "3c980f87-33b4-4a50-e2e3-2232b31a4248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando modelo con Bag of Words...\n",
            "✓ Modelo BoW entrenado.\n",
            "\n",
            "Entrenando modelo con TF-IDF...\n",
            "✓ Modelo TF-IDF entrenado.\n"
          ]
        }
      ],
      "source": [
        "# Modelo 1: Regresión Logística con Bag of Words\n",
        "print(\"Entrenando modelo con Bag of Words...\")\n",
        "clf_bow = LogisticRegression(max_iter=1000, random_state=42)\n",
        "clf_bow.fit(X_train_counts, sentiment_train)\n",
        "print(\"✓ Modelo BoW entrenado.\\n\")\n",
        "\n",
        "# Modelo 2: Regresión Logística con TF-IDF\n",
        "print(\"Entrenando modelo con TF-IDF...\")\n",
        "clf_tfidf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "clf_tfidf.fit(X_train_tfidf, sentiment_train)\n",
        "print(\"✓ Modelo TF-IDF entrenado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCY7kLi0ih3y"
      },
      "source": [
        "---\n",
        "\n",
        "## 7️⃣ Evaluación de los Modelos\n",
        "\n",
        "Evaluamos ambos modelos en el conjunto de prueba (datos que nunca vieron durante el entrenamiento).\n",
        "\n",
        "### Métricas:\n",
        "\n",
        "1. **Accuracy**: Porcentaje de predicciones correctas\n",
        "2. **Precision**: De las reseñas que predijimos como positivas, ¿cuántas lo son realmente?\n",
        "3. **Recall**: De todas las reseñas positivas reales, ¿cuántas detectamos?\n",
        "4. **F1-score**: Media armónica entre precision y recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4SS0uqpih3y",
        "outputId": "1b77db86-16f3-44e9-c8b0-213e1f00e2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "RESULTADOS DE EVALUACIÓN\n",
            "============================================================\n",
            "\n",
            "Accuracy con Bag of Words:  1.0000 (100.00%)\n",
            "Accuracy con TF-IDF:        0.9939 (99.39%)\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Predicciones de ambos modelos\n",
        "y_pred_bow = clf_bow.predict(X_test_counts)\n",
        "y_pred_tfidf = clf_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "accuracy_bow = accuracy_score(sentiment_test, y_pred_bow)\n",
        "accuracy_tfidf = accuracy_score(sentiment_test, y_pred_tfidf)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"RESULTADOS DE EVALUACIÓN\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nAccuracy con Bag of Words:  {accuracy_bow:.4f} ({accuracy_bow*100:.2f}%)\")\n",
        "print(f\"Accuracy con TF-IDF:        {accuracy_tfidf:.4f} ({accuracy_tfidf*100:.2f}%)\")\n",
        "print(\"\\n\" + \"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj8yNkrkih3y"
      },
      "source": [
        "### Reporte de clasificación detallado (TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jdIDI0Uih3z",
        "outputId": "47587938-c335-49ad-cb05-8b3632efbf41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "REPORTE DETALLADO - MODELO TF-IDF\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Negativo (0)       0.99      1.00      0.99        82\n",
            "Positivo (1)       1.00      0.99      0.99        82\n",
            "\n",
            "    accuracy                           0.99       164\n",
            "   macro avg       0.99      0.99      0.99       164\n",
            "weighted avg       0.99      0.99      0.99       164\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nREPORTE DETALLADO - MODELO TF-IDF\")\n",
        "print(\"=\" * 60)\n",
        "print(classification_report(sentiment_test, y_pred_tfidf,\n",
        "                          target_names=['Negativo (0)', 'Positivo (1)']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtcOI2lnih3z"
      },
      "source": [
        "### Matriz de confusión\n",
        "\n",
        "La matriz de confusión muestra dónde se equivoca el modelo:\n",
        "\n",
        "```\n",
        "                Predicho Neg    Predicho Pos\n",
        "Real Neg             VN              FP\n",
        "Real Pos             FN              VP\n",
        "```\n",
        "\n",
        "- **VP (Verdaderos Positivos)**: Correctamente clasificados como positivos\n",
        "- **VN (Verdaderos Negativos)**: Correctamente clasificados como negativos\n",
        "- **FP (Falsos Positivos)**: Negativos clasificados erróneamente como positivos\n",
        "- **FN (Falsos Negativos)**: Positivos clasificados erróneamente como negativos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH7CIkBZih3z",
        "outputId": "3cb25358-2fb6-4223-df55-129474cfcdd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MATRIZ DE CONFUSIÓN - MODELO TF-IDF\n",
            "============================================================\n",
            "\n",
            "[[82  0]\n",
            " [ 1 81]]\n",
            "\n",
            "Verdaderos Negativos: 82\n",
            "Falsos Positivos:     0\n",
            "Falsos Negativos:     1\n",
            "Verdaderos Positivos: 81\n"
          ]
        }
      ],
      "source": [
        "cm = confusion_matrix(sentiment_test, y_pred_tfidf)\n",
        "\n",
        "print(\"MATRIZ DE CONFUSIÓN - MODELO TF-IDF\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n{cm}\\n\")\n",
        "print(f\"Verdaderos Negativos: {cm[0,0]}\")\n",
        "print(f\"Falsos Positivos:     {cm[0,1]}\")\n",
        "print(f\"Falsos Negativos:     {cm[1,0]}\")\n",
        "print(f\"Verdaderos Positivos: {cm[1,1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4oJhptpih3z"
      },
      "source": [
        "---\n",
        "\n",
        "## 8️⃣ Predicciones sobre Datos Nuevos en Español\n",
        "\n",
        "Ahora que tenemos un modelo entrenado, podemos clasificar reseñas nuevas en español que nunca vio antes. Este es el objetivo final: generalizar a datos del mundo real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwK5Iwslih3z",
        "outputId": "ff38c10c-c5d6-4026-b44d-3d9ce8ec3e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "PREDICCIONES SOBRE RESEÑAS NUEVAS EN ESPAÑOL\n",
            "================================================================================\n",
            "\n",
            "Reseña: \"Excelente producto, superó mis expectativas. Lo recomiendo totalmente.\"\n",
            "Predicción: POSITIVO ✓ (Confianza: 87.1%)\n",
            "\n",
            "Reseña: \"Malísima calidad, se rompió a los pocos días. No lo compren.\"\n",
            "Predicción: NEGATIVO ✗ (Confianza: 88.0%)\n",
            "\n",
            "Reseña: \"Es aceptable, cumple su función pero nada del otro mundo.\"\n",
            "Predicción: POSITIVO ✓ (Confianza: 62.9%)\n",
            "\n",
            "Reseña: \"Me encantó, justo lo que buscaba. Llegó rápido y bien empaquetado.\"\n",
            "Predicción: POSITIVO ✓ (Confianza: 66.9%)\n",
            "\n",
            "Reseña: \"Decepcionante, no funciona como dice la descripción. Pérdida de dinero.\"\n",
            "Predicción: NEGATIVO ✗ (Confianza: 85.7%)\n",
            "\n",
            "Reseña: \"Buenísimo, la mejor compra que podes hacer si queres tirar tu dinero a la basura.\"\n",
            "Predicción: NEGATIVO ✗ (Confianza: 51.1%)\n",
            "\n",
            "Reseña: \"Horrible, el peor producto que compré. No sirve para nada.\"\n",
            "Predicción: NEGATIVO ✗ (Confianza: 89.9%)\n"
          ]
        }
      ],
      "source": [
        "# Nuevas reseñas de ejemplo en español\n",
        "new_reviews = [\n",
        "    \"Excelente producto, superó mis expectativas. Lo recomiendo totalmente.\",\n",
        "    \"Malísima calidad, se rompió a los pocos días. No lo compren.\",\n",
        "    \"Es aceptable, cumple su función pero nada del otro mundo.\",\n",
        "    \"Me encantó, justo lo que buscaba. Llegó rápido y bien empaquetado.\",\n",
        "    \"Decepcionante, no funciona como dice la descripción. Pérdida de dinero.\",\n",
        "    \"Buenísimo, la mejor compra que podes hacer si queres tirar tu dinero a la basura.\",\n",
        "    \"Horrible, el peor producto que compré. No sirve para nada.\"\n",
        "]\n",
        "\n",
        "# Vectorizamos con el MISMO vectorizador entrenado\n",
        "# ¡NUNCA usar fit() en datos nuevos! Solo transform()\n",
        "X_new = tfidf_vectorizer.transform(new_reviews)\n",
        "\n",
        "# Predicciones y probabilidades\n",
        "predictions = clf_tfidf.predict(X_new)\n",
        "probabilities = clf_tfidf.predict_proba(X_new)\n",
        "\n",
        "# Mostramos resultados\n",
        "print(\"=\" * 80)\n",
        "print(\"PREDICCIONES SOBRE RESEÑAS NUEVAS EN ESPAÑOL\")\n",
        "print(\"=\" * 80)\n",
        "for i, review in enumerate(new_reviews):\n",
        "    sentiment_label = \"POSITIVO ✓\" if predictions[i] == 1 else \"NEGATIVO ✗\"\n",
        "    confidence = probabilities[i][predictions[i]] * 100\n",
        "    print(f\"\\nReseña: \\\"{review}\\\"\")\n",
        "    print(f\"Predicción: {sentiment_label} (Confianza: {confidence:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bIp2YQ5ih3z"
      },
      "source": [
        "---\n",
        "\n",
        "## 9️⃣ Interpretabilidad: ¿Qué Palabras Importan?\n",
        "\n",
        "Una ventaja de la Regresión Logística es que podemos inspeccionar los pesos del modelo para entender qué palabras en español considera más importantes para cada clase.\n",
        "\n",
        "**💡 Ejercicio pedagógico**: Después de ver las palabras más influyentes, analicemos por qué el modelo puede fallar en casos de ironía y sarcasmo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjoqq0pCih3z",
        "outputId": "b402a648-a5d3-409d-8c05-618f5e63a672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PALABRAS MÁS INFLUYENTES EN LAS PREDICCIONES\n",
            "============================================================\n",
            "\n",
            "Top 15 palabras asociadas con SENTIMIENTO POSITIVO:\n",
            "  ✓ mis                  (peso: 1.8547)\n",
            "  ✓ fue                  (peso: 1.6596)\n",
            "  ✓ este                 (peso: 1.6196)\n",
            "  ✓ me                   (peso: 1.5042)\n",
            "  ✓ compra               (peso: 1.4989)\n",
            "  ✓ perfecto             (peso: 1.4730)\n",
            "  ✓ todos                (peso: 1.4304)\n",
            "  ✓ sigue                (peso: 1.2932)\n",
            "  ✓ perfectamente        (peso: 1.1302)\n",
            "  ✓ estado               (peso: 1.1227)\n",
            "  ✓ antes                (peso: 1.1227)\n",
            "  ✓ resultó              (peso: 1.0945)\n",
            "  ✓ total                (peso: 1.0659)\n",
            "  ✓ ganga                (peso: 1.0659)\n",
            "  ✓ ser                  (peso: 1.0384)\n",
            "\n",
            "Top 15 palabras asociadas con SENTIMIENTO NEGATIVO:\n",
            "  ✗ no                   (peso: -2.3939)\n",
            "  ✗ se                   (peso: -2.0986)\n",
            "  ✗ para                 (peso: -2.0375)\n",
            "  ✗ un                   (peso: -1.7465)\n",
            "  ✗ las                  (peso: -1.4123)\n",
            "  ✗ ni                   (peso: -1.3164)\n",
            "  ✗ rompió               (peso: -1.3142)\n",
            "  ✗ descripción          (peso: -1.2254)\n",
            "  ✗ inferior             (peso: -1.2254)\n",
            "  ✗ plata                (peso: -1.2234)\n",
            "  ✗ algo                 (peso: -1.2174)\n",
            "  ✗ decepcionante        (peso: -1.2063)\n",
            "  ✗ partes               (peso: -1.1361)\n",
            "  ✗ golpeado             (peso: -1.1361)\n",
            "  ✗ faltantes            (peso: -1.1361)\n",
            "\n",
            "============================================================\n",
            "💡 ANÁLISIS PEDAGÓGICO\n",
            "============================================================\n",
            "\n",
            "El modelo aprendió correctamente que palabras como 'excelente', 'perfecto',\n",
            "'genial' están asociadas con sentimiento POSITIVO.\n",
            "\n",
            "Sin embargo, esto es también su DEBILIDAD:\n",
            "\n",
            "En una reseña irónica como:\n",
            "  \"Excelente si querés tirar la plata a la basura\"\n",
            "  \n",
            "El modelo verá 'excelente' (peso positivo alto) y probablemente \n",
            "la clasifique INCORRECTAMENTE como positiva, porque:\n",
            "\n",
            "1. BoW/TF-IDF ignoran el ORDEN de las palabras\n",
            "2. No capturan el CONTEXTO (\"si querés tirar la plata\")\n",
            "3. No entienden NEGACIONES ni IRONÍA\n",
            "\n",
            "Esto motiva el uso de modelos más avanzados (LSTM, Transformers)\n",
            "que veremos en los próximos notebooks.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Obtenemos features (palabras) y coeficientes\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "coefficients = clf_tfidf.coef_[0]\n",
        "\n",
        "# Top 15 palabras más positivas y negativas\n",
        "top_positive_indices = np.argsort(coefficients)[-15:]\n",
        "top_negative_indices = np.argsort(coefficients)[:15]\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PALABRAS MÁS INFLUYENTES EN LAS PREDICCIONES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nTop 15 palabras asociadas con SENTIMIENTO POSITIVO:\")\n",
        "for idx in reversed(top_positive_indices):\n",
        "    print(f\"  ✓ {feature_names[idx]:20s} (peso: {coefficients[idx]:.4f})\")\n",
        "\n",
        "print(\"\\nTop 15 palabras asociadas con SENTIMIENTO NEGATIVO:\")\n",
        "for idx in top_negative_indices:\n",
        "    print(f\"  ✗ {feature_names[idx]:20s} (peso: {coefficients[idx]:.4f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"💡 ANÁLISIS PEDAGÓGICO\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\"\"\n",
        "El modelo aprendió correctamente que palabras como 'excelente', 'perfecto',\n",
        "'genial' están asociadas con sentimiento POSITIVO.\n",
        "\n",
        "Sin embargo, esto es también su DEBILIDAD:\n",
        "\n",
        "En una reseña irónica como:\n",
        "  \"Excelente si querés tirar la plata a la basura\"\n",
        "\n",
        "El modelo verá 'excelente' (peso positivo alto) y probablemente\n",
        "la clasifique INCORRECTAMENTE como positiva, porque:\n",
        "\n",
        "1. BoW/TF-IDF ignoran el ORDEN de las palabras\n",
        "2. No capturan el CONTEXTO (\"si querés tirar la plata\")\n",
        "3. No entienden NEGACIONES ni IRONÍA\n",
        "\n",
        "Esto motiva el uso de modelos más avanzados (LSTM, Transformers)\n",
        "que veremos en los próximos notebooks.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agregamos las predicciones al dataframe de test\n",
        "# Necesitamos identificar los índices del test set en el df original\n",
        "test_indices = []\n",
        "for review in reviews_test:\n",
        "    # Encontramos el índice en df\n",
        "    idx = df[df['review_body'] == review].index[0]\n",
        "    test_indices.append(idx)\n",
        "\n",
        "df_test = df.loc[test_indices].copy()\n",
        "df_test['prediccion'] = y_pred_tfidf\n",
        "\n",
        "# Calculamos accuracy por tipo de review\n",
        "print(\"=\" * 70)\n",
        "print(\"RENDIMIENTO DEL MODELO POR TIPO DE RESEÑA\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for tipo in sorted(df_test['tipo'].unique()):\n",
        "    df_tipo = df_test[df_test['tipo'] == tipo]\n",
        "    if len(df_tipo) > 0:\n",
        "        aciertos = (df_tipo['sentiment'] == df_tipo['prediccion']).sum()\n",
        "        total = len(df_tipo)\n",
        "        accuracy_tipo = aciertos / total * 100\n",
        "\n",
        "        # Clasificamos dificultad\n",
        "        if 'simple' in tipo:\n",
        "            dificultad = \"FÁCIL     \"\n",
        "        elif 'ironia' in tipo:\n",
        "            dificultad = \"DIFÍCIL   \"\n",
        "        else:  # negacion\n",
        "            dificultad = \"MUY DIFÍCIL\"\n",
        "\n",
        "        print(f\"\\n{tipo:25s} [{dificultad}]: {accuracy_tipo:5.1f}% ({aciertos}/{total})\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"💡 OBSERVACIONES PEDAGÓGICAS\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "Como era de esperarse:\n",
        "\n",
        "✓ CASOS SIMPLES: Alta precisión (~85-95%)\n",
        "  El modelo funciona bien cuando las palabras coinciden con el sentimiento.\n",
        "\n",
        "⚠ IRONÍA/SARCASMO: Precisión media-baja (~50-70%)\n",
        "  El modelo se confunde porque las palabras no coinciden con el sentimiento real.\n",
        "\n",
        "✗ NEGACIONES: Precisión variable\n",
        "  \"No funciona\" vs \"No tengo quejas\" - ambas tienen \"no\", pero significan opuesto.\n",
        "\n",
        "CONCLUSIÓN: Los modelos clásicos (TF-IDF + Logistic Regression) son un\n",
        "buen BASELINE, pero tienen limitaciones claras con casos complejos.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy0M7JNaih3z",
        "outputId": "678da912-9f15-48eb-f7fc-77790d8fe9f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "RENDIMIENTO DEL MODELO POR TIPO DE RESEÑA\n",
            "======================================================================\n",
            "\n",
            "ambiguo_negativo          [MUY DIFÍCIL]: 100.0% (6/6)\n",
            "\n",
            "ambiguo_positivo          [MUY DIFÍCIL]: 100.0% (7/7)\n",
            "\n",
            "ironia_negativo           [DIFÍCIL   ]: 100.0% (16/16)\n",
            "\n",
            "ironia_positivo           [DIFÍCIL   ]: 100.0% (11/11)\n",
            "\n",
            "negacion_negativo         [MUY DIFÍCIL]: 100.0% (7/7)\n",
            "\n",
            "negacion_positivo         [MUY DIFÍCIL]:  93.3% (14/15)\n",
            "\n",
            "simple_negativo           [FÁCIL     ]: 100.0% (53/53)\n",
            "\n",
            "simple_positivo           [FÁCIL     ]: 100.0% (49/49)\n",
            "\n",
            "======================================================================\n",
            "💡 OBSERVACIONES PEDAGÓGICAS\n",
            "======================================================================\n",
            "\n",
            "Como era de esperarse:\n",
            "\n",
            "✓ CASOS SIMPLES: Alta precisión (~85-95%)\n",
            "  El modelo funciona bien cuando las palabras coinciden con el sentimiento.\n",
            "\n",
            "⚠ IRONÍA/SARCASMO: Precisión media-baja (~50-70%)\n",
            "  El modelo se confunde porque las palabras no coinciden con el sentimiento real.\n",
            "\n",
            "✗ NEGACIONES: Precisión variable\n",
            "  \"No funciona\" vs \"No tengo quejas\" - ambas tienen \"no\", pero significan opuesto.\n",
            "\n",
            "CONCLUSIÓN: Los modelos clásicos (TF-IDF + Logistic Regression) son un \n",
            "buen BASELINE, pero tienen limitaciones claras con casos complejos.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis de Rendimiento por Tipo de Reseña\n",
        "\n",
        "Veamos cómo le va al modelo en diferentes tipos de casos."
      ],
      "metadata": {
        "id": "Ty_UnOeXih30"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enLatDUTih30"
      },
      "source": [
        "---\n",
        "\n",
        "## 🧠 Guía Teórico-Conceptual\n",
        "\n",
        "### 1. Flujo completo de un proyecto de clasificación de texto\n",
        "\n",
        "**Paso 1: Recolección de datos**  \n",
        "Obtener un corpus etiquetado (en nuestro caso, reseñas con sentimiento)\n",
        "\n",
        "**Paso 2: Preprocesamiento**  \n",
        "Limpiar texto, tokenización, opcional: stemming/lemmatización\n",
        "\n",
        "**Paso 3: Vectorización**  \n",
        "Convertir texto en representación numérica (BoW, TF-IDF, embeddings)\n",
        "\n",
        "**Paso 4: División train/test**  \n",
        "Separar datos para entrenar y evaluar sin sesgo\n",
        "\n",
        "**Paso 5: Entrenamiento**  \n",
        "Ajustar modelo a los datos de entrenamiento\n",
        "\n",
        "**Paso 6: Evaluación**  \n",
        "Medir rendimiento en datos de prueba\n",
        "\n",
        "**Paso 7: Optimización**  \n",
        "Ajustar hiperparámetros, probar otros modelos\n",
        "\n",
        "**Paso 8: Despliegue**  \n",
        "Usar el modelo en producción\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Bag of Words vs. TF-IDF\n",
        "\n",
        "**Bag of Words (BoW):**\n",
        "- Representa documentos como vectores de conteos de palabras\n",
        "- Ignora orden y gramática\n",
        "- Simple pero efectivo como baseline\n",
        "- **Problema**: Palabras muy frecuentes dominan la representación\n",
        "\n",
        "**TF-IDF:**\n",
        "- Balancea frecuencia local (documento) con rareza global (corpus)\n",
        "- Palabras comunes reciben pesos bajos\n",
        "- Palabras discriminativas reciben pesos altos\n",
        "- Generalmente supera a BoW en clasificación de texto\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Regresión Logística para Clasificación\n",
        "\n",
        "**Funcionamiento:**\n",
        "- Aprende función lineal: z = w₁x₁ + w₂x₂ + ... + wₙxₙ + b\n",
        "- Aplica sigmoide: P(y=1|x) = 1 / (1 + e⁻ᶻ)\n",
        "- Salida es probabilidad entre 0 y 1\n",
        "- Si P > 0.5 → Clase 1, sino → Clase 0\n",
        "\n",
        "**Ventajas:**\n",
        "- Rápido y eficiente\n",
        "- Probabilidades calibradas\n",
        "- Pesos interpretables\n",
        "- Funciona bien con alta dimensionalidad\n",
        "\n",
        "**Limitaciones:**\n",
        "- Asume relaciones lineales\n",
        "- No captura interacciones complejas\n",
        "- Ignora orden de palabras\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Métricas de Evaluación\n",
        "\n",
        "**Accuracy:** Porcentaje de predicciones correctas (cuidado con clases desbalanceadas)\n",
        "\n",
        "**Precision:** De las predichas positivas, ¿cuántas son realmente positivas?\n",
        "\n",
        "**Recall:** De las positivas reales, ¿cuántas detectamos?\n",
        "\n",
        "**F1-Score:** Media armónica entre precision y recall\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Importancia del Baseline\n",
        "\n",
        "Antes de usar redes neuronales complejas, siempre establecemos un baseline simple para:\n",
        "\n",
        "1. Entender la dificultad del problema\n",
        "2. Detectar problemas en los datos\n",
        "3. Tener punto de comparación cuantitativo\n",
        "4. Justificar complejidad adicional\n",
        "5. Iterar rápidamente\n",
        "\n",
        "En muchos casos, un modelo simple bien ajustado es suficiente y preferible (más rápido, interpretable, fácil de mantener)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlDw1D1qih30"
      },
      "source": [
        "---\n",
        "\n",
        "## ❓ Preguntas y Respuestas para Estudio\n",
        "\n",
        "### Preguntas Conceptuales\n",
        "\n",
        "**1. ¿Por qué es importante dividir los datos en conjuntos de entrenamiento y prueba?**\n",
        "\n",
        "*Respuesta:* Para evaluar el rendimiento del modelo en datos que nunca vio durante el entrenamiento. Si evaluáramos con los mismos datos de entrenamiento, el modelo podría haber memorizado los ejemplos (overfitting) y no generalizar bien a datos nuevos del mundo real.\n",
        "\n",
        "---\n",
        "\n",
        "**2. ¿Cuál es la diferencia principal entre Bag of Words y TF-IDF?**\n",
        "\n",
        "*Respuesta:* BoW solo cuenta la frecuencia de cada palabra en el documento, mientras que TF-IDF pondera esa frecuencia según qué tan rara es la palabra en todo el corpus. TF-IDF reduce la importancia de palabras muy comunes (como \"el\", \"de\") y aumenta la de palabras discriminativas.\n",
        "\n",
        "---\n",
        "\n",
        "**3. ¿Por qué usamos Regresión Logística para clasificación si su nombre dice \"regresión\"?**\n",
        "\n",
        "*Respuesta:* Aunque el nombre es confuso, la Regresión Logística es un algoritmo de clasificación. Usa una función logística (sigmoide) para convertir una combinación lineal de features en una probabilidad entre 0 y 1, y luego clasifica según un umbral (típicamente 0.5).\n",
        "\n",
        "---\n",
        "\n",
        "**4. ¿Qué es el overfitting y cómo lo evitamos en este notebook?**\n",
        "\n",
        "*Respuesta:* Overfitting ocurre cuando el modelo memoriza los datos de entrenamiento en lugar de aprender patrones generalizables. Lo evitamos mediante: (1) división train/test, (2) limitación del vocabulario (max_features=1000), y (3) regularización implícita en LogisticRegression.\n",
        "\n",
        "---\n",
        "\n",
        "**5. ¿Por qué nunca debemos usar fit() en los datos de prueba?**\n",
        "\n",
        "*Respuesta:* Porque fit() aprende parámetros de los datos (vocabulario, escalas, etc.). Si lo usamos en datos de prueba, el modelo \"espía\" información que no debería conocer, invalidando la evaluación. Solo debemos usar transform() en datos nuevos.\n",
        "\n",
        "---\n",
        "\n",
        "### Preguntas Técnicas\n",
        "\n",
        "**6. Si tenemos un dataset con 90% de reseñas positivas y 10% negativas, ¿qué problema tiene usar solo accuracy como métrica?**\n",
        "\n",
        "*Respuesta:* Un modelo trivial que prediga \"positivo\" para todo tendría 90% de accuracy sin aprender nada útil. En datasets desbalanceados, debemos usar precision, recall y F1-score para evaluar el rendimiento en cada clase.\n",
        "\n",
        "---\n",
        "\n",
        "**7. ¿Qué significa que TfidfVectorizer devuelva una \"matriz dispersa\" (sparse matrix)?**\n",
        "\n",
        "*Respuesta:* Como la mayoría de las entradas son cero (cada documento solo contiene una pequeña fracción del vocabulario total), scipy usa una representación dispersa que solo almacena los valores no-cero. Esto ahorra memoria y acelera cálculos.\n",
        "\n",
        "---\n",
        "\n",
        "**8. ¿Cómo interpretamos los coeficientes de la Regresión Logística?**\n",
        "\n",
        "*Respuesta:* Coeficientes positivos indican que la presencia de esa palabra aumenta la probabilidad de clase positiva. Coeficientes negativos indican asociación con la clase negativa. La magnitud indica la fuerza de la asociación.\n",
        "\n",
        "---\n",
        "\n",
        "**9. ¿Qué pasaría si no usáramos random_state en train_test_split?**\n",
        "\n",
        "*Respuesta:* Cada ejecución del notebook produciría una división diferente, resultando en métricas ligeramente distintas. Fijar random_state garantiza reproducibilidad, importante para debugging y comparación de modelos.\n",
        "\n",
        "---\n",
        "\n",
        "**10. ¿Por qué limitamos max_features a 1000 palabras?**\n",
        "\n",
        "*Respuesta:* Para reducir dimensionalidad y evitar overfitting. Palabras muy raras (que aparecen en 1-2 documentos) suelen ser ruido o typos. Mantener solo las más frecuentes captura la mayor parte de la información con menor riesgo de sobreajuste.\n",
        "\n",
        "---\n",
        "\n",
        "### Preguntas de Aplicación\n",
        "\n",
        "**11. Mencioná tres limitaciones del enfoque BoW/TF-IDF que las redes neuronales podrían superar.**\n",
        "\n",
        "*Respuesta:*\n",
        "1. Ignoran el orden de las palabras (\"no es bueno\" vs \"es bueno\")\n",
        "2. No capturan significado semántico (\"excelente\" y \"genial\" son tratadas como completamente diferentes)\n",
        "3. No modelan dependencias largas ni contexto complejo\n",
        "\n",
        "---\n",
        "\n",
        "**12. Si tuvieras que clasificar tweets (textos muy cortos), ¿qué ajustes harías a este enfoque?**\n",
        "\n",
        "*Respuesta:*\n",
        "- Incluir n-gramas (bigramas, trigramas) para capturar frases cortas\n",
        "- Reducir max_features (menos palabras únicas en tweets)\n",
        "- Considerar preprocesamiento de hashtags, menciones y emojis\n",
        "- Probar con char-level features para manejar jerga y typos\n",
        "\n",
        "---\n",
        "\n",
        "**13. ¿En qué casos preferirías usar Regresión Logística sobre una red neuronal profunda?**\n",
        "\n",
        "*Respuesta:*\n",
        "- Dataset pequeño (pocas muestras)\n",
        "- Necesidad de interpretabilidad (explicar decisiones)\n",
        "- Recursos computacionales limitados\n",
        "- Necesidad de entrenar/desplegar rápidamente\n",
        "- Cuando el baseline ya da resultados satisfactorios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gvPmp6-ih30"
      },
      "source": [
        "---\n",
        "\n",
        "## 🎯 Ejercicios Propuestos\n",
        "\n",
        "### Ejercicio 1: Experimentación con Hiperparámetros\n",
        "Probá cambiar `max_features` en TfidfVectorizer a 500, 2000 y 5000. ¿Cómo afecta al accuracy? ¿Observás overfitting con vocabularios muy grandes?\n",
        "\n",
        "### Ejercicio 2: N-gramas\n",
        "Modificá TfidfVectorizer para incluir bigramas: `TfidfVectorizer(max_features=1000, ngram_range=(1,2))`. ¿Mejora el rendimiento? ¿Por qué los bigramas pueden ser útiles en español?\n",
        "\n",
        "### Ejercicio 3: Dataset Completo\n",
        "Probá entrenar con el dataset completo (200,000 reviews) en lugar del subset de 10,000. ¿Mejora significativamente el accuracy? ¿Cuánto tarda el entrenamiento?\n",
        "\n",
        "### Ejercicio 4: Análisis de Errores\n",
        "Identificá 5 reseñas del conjunto de prueba que el modelo clasificó incorrectamente. ¿Qué tienen en común? ¿Son casos difíciles incluso para humanos? (Tip: ironía, sarcasmo, negaciones)\n",
        "\n",
        "### Ejercicio 5: Comparación de Modelos\n",
        "Probá otros clasificadores de sklearn: `MultinomialNB`, `SVC`, `RandomForestClassifier`. ¿Cuál da mejores resultados en español? ¿Cuál es más rápido?\n",
        "\n",
        "### Ejercicio 6: Dataset Propio\n",
        "Buscá otro dataset en español (Twitter, reviews de apps, noticias) y aplicá el mismo pipeline. ¿El modelo generaliza bien a otros dominios?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfrigcGaih30"
      },
      "source": [
        "## 🎓 Conclusión\n",
        "\n",
        "En este notebook establecimos un baseline sólido para clasificación de sentimientos en español usando métodos clásicos de Machine Learning. Aprendimos:\n",
        "\n",
        "1. ✅ Cargar datasets de HuggingFace con reviews reales en español\n",
        "2. ✅ Preprocesar datos y convertir problemas multiclase a binarios\n",
        "3. ✅ Vectorizar texto con BoW y TF-IDF\n",
        "4. ✅ Entrenar modelos de Regresión Logística\n",
        "5. ✅ Evaluar con métricas apropiadas\n",
        "6. ✅ Interpretar qué palabras en español influyen en las predicciones\n",
        "\n",
        "**Próximo paso:** En el siguiente notebook vamos a explorar Naive Bayes y Pipelines de sklearn para construir flujos de trabajo más modulares y profesionales.\n",
        "\n",
        "---\n",
        "\n",
        "### 💡 Reflexión Final\n",
        "\n",
        "Este modelo clásico (TF-IDF + Logistic Regression) es sorprendentemente efectivo para clasificación de sentimientos. En muchos casos reales de la industria, un baseline bien ajustado como este es suficiente y preferible por su:\n",
        "\n",
        "- ⚡ Velocidad de entrenamiento e inferencia\n",
        "- 📊 Interpretabilidad (podemos explicar por qué clasifica así)\n",
        "- 💻 Bajos requisitos computacionales\n",
        "- 🔧 Facilidad de mantenimiento\n",
        "\n",
        "Solo cuando este baseline no alcanza la performance requerida, justificamos la complejidad adicional de redes neuronales profundas.\n",
        "\n",
        "---\n",
        "\n",
        "*Este material fue desarrollado con fines educativos para la Tecnicatura en Ciencia de Datos del IFTS.*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}