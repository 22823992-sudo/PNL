{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {
        "id": "cell-0"
      },
      "source": [
        "# Clasificación de Sentimientos con una Red Neuronal Multicapa (MLP)\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "En esta actividad vas a construir una red neuronal feedforward multicapa (MLP) usando PyTorch. El objetivo es entrenarla para que pueda clasificar frases en español como positivas o negativas.\n",
        "\n",
        "### Con esto vas a:\n",
        "\n",
        "- Comprender cómo se construye una red con múltiples capas y neuronas\n",
        "- Usar funciones de activación no lineales (ReLU, Sigmoid)\n",
        "- Implementar entrenamiento automático con optimizadores modernos\n",
        "- Observar cómo una MLP mejora respecto al perceptrón simple del laboratorio anterior\n",
        "\n",
        "### ¿Qué es una red neuronal multicapa?\n",
        "\n",
        "A diferencia del perceptrón simple (una sola neurona), una MLP tiene:\n",
        "- **Capa de entrada**: Recibe los features del texto\n",
        "- **Capas ocultas**: Una o más capas intermedias que aprenden representaciones complejas\n",
        "- **Capa de salida**: Produce la predicción final\n",
        "\n",
        "Las capas ocultas permiten aprender patrones **no lineales**, lo que le da mucha más capacidad expresiva al modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-1",
      "metadata": {
        "id": "cell-1"
      },
      "source": [
        "## 1. Preparación del entorno\n",
        "\n",
        "Importamos PyTorch y NumPy para comenzar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-2",
        "outputId": "0395fd2f-4248-4444-c781-f716a8db258f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch versión: 2.8.0+cu126\n",
            "Device disponible: CPU\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "print(f\"PyTorch versión: {torch.__version__}\")\n",
        "print(f\"Device disponible: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {
        "id": "cell-3"
      },
      "source": [
        "## 2. Datos de entrenamiento\n",
        "\n",
        "Usamos un conjunto más grande de frases típicas de opiniones escritas en Argentina, etiquetadas como positivas (1) o negativas (0).\n",
        "\n",
        "Vamos a incluir casos más variados y complejos que en el laboratorio anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-4",
        "outputId": "1137a987-262f-4be1-fc6e-02d6c2fbe8ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de frases: 10\n",
            "Balance: 5 positivas, 5 negativas\n",
            "\n",
            "Ejemplos:\n",
            "  1. 'La verdad, este lugar está bárbaro. Muy recomendable' → Positivo\n",
            "  2. 'Una porquería de servicio, nunca más vuelvo' → Negativo\n",
            "  3. 'Me encantó la comida, aunque la música estaba muy fuerte' → Positivo\n"
          ]
        }
      ],
      "source": [
        "frases = [\n",
        "    \"La verdad, este lugar está bárbaro. Muy recomendable\",\n",
        "    \"Una porquería de servicio, nunca más vuelvo\",\n",
        "    \"Me encantó la comida, aunque la música estaba muy fuerte\",\n",
        "    \"El envío fue lento y el producto llegó dañado. Qué desastre\",\n",
        "    \"Todo excelente. Atención de diez\",\n",
        "    \"Qué estafa, me arrepiento de haber comprado\",\n",
        "    \"Muy conforme con el resultado final\",\n",
        "    \"No me gustó para nada la experiencia\",\n",
        "    \"Superó mis expectativas, gracias\",\n",
        "    \"No lo recomiendo, mala calidad\"\n",
        "]\n",
        "\n",
        "etiquetas = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])  # 1 = Positivo, 0 = Negativo\n",
        "\n",
        "print(f\"Total de frases: {len(frases)}\")\n",
        "print(f\"Balance: {sum(etiquetas)} positivas, {len(etiquetas) - sum(etiquetas)} negativas\\n\")\n",
        "print(\"Ejemplos:\")\n",
        "for i in range(3):\n",
        "    sentimiento = \"Positivo\" if etiquetas[i] == 1 else \"Negativo\"\n",
        "    print(f\"  {i+1}. '{frases[i]}' → {sentimiento}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-5",
      "metadata": {
        "id": "cell-5"
      },
      "source": [
        "## 3. Construcción del vocabulario\n",
        "\n",
        "Definimos manualmente un vocabulario con palabras que suelen aparecer en frases de opinión con carga positiva o negativa.\n",
        "\n",
        "En este caso expandimos el vocabulario para cubrir más términos comunes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-6",
        "outputId": "23b70938-ca6b-4549-f8cc-1c1edbb85e8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario: 16 palabras clave\n",
            "\n",
            "Palabras: ['bárbaro', 'recomendable', 'porquería', 'nunca', 'encantó', 'fuerte', 'desastre', 'excelente', 'estafa', 'arrepiento', 'conforme', 'gustó', 'superó', 'gracias', 'recomiendo', 'mala']\n"
          ]
        }
      ],
      "source": [
        "vocabulario = [\n",
        "    \"bárbaro\", \"recomendable\", \"porquería\", \"nunca\", \"encantó\",\n",
        "    \"fuerte\", \"desastre\", \"excelente\", \"estafa\", \"arrepiento\",\n",
        "    \"conforme\", \"gustó\", \"superó\", \"gracias\", \"recomiendo\", \"mala\"\n",
        "]\n",
        "\n",
        "print(f\"Vocabulario: {len(vocabulario)} palabras clave\")\n",
        "print(f\"\\nPalabras: {vocabulario}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-7",
      "metadata": {
        "id": "cell-7"
      },
      "source": [
        "## 4. Preprocesamiento: vectorización de las frases\n",
        "\n",
        "Seguimos usando bag-of-words como en el laboratorio anterior: cada frase se convierte en un vector binario que indica si contiene alguna de las palabras del vocabulario.\n",
        "\n",
        "Luego convertimos estos vectores a tensores de PyTorch para poder usarlos con redes neuronales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-8",
        "outputId": "80dae58f-4f1d-4eed-c799-ee09a6782158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos preprocesados:\n",
            "  X shape: torch.Size([10, 16]) (frases × features)\n",
            "  y shape: torch.Size([10, 1]) (frases × 1)\n",
            "\n",
            "Primera frase vectorizada: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "Etiqueta: 1.0\n"
          ]
        }
      ],
      "source": [
        "def vectorizar(frase, vocabulario):\n",
        "    \"\"\"\n",
        "    Convierte una frase en un vector binario según el vocabulario.\n",
        "\n",
        "    Args:\n",
        "        frase: String con la frase a vectorizar\n",
        "        vocabulario: Lista de palabras clave\n",
        "\n",
        "    Returns:\n",
        "        Array de numpy con 1s y 0s (float32 para PyTorch)\n",
        "    \"\"\"\n",
        "    tokens = frase.lower().split()\n",
        "    return np.array([1 if palabra in tokens else 0 for palabra in vocabulario], dtype=np.float32)\n",
        "\n",
        "# Vectorizamos todas las frases\n",
        "X_np = np.array([vectorizar(frase, vocabulario) for frase in frases], dtype=np.float32)\n",
        "y_np = etiquetas.astype(np.float32).reshape(-1, 1)\n",
        "\n",
        "# Convertimos a tensores de PyTorch\n",
        "X = torch.tensor(X_np)\n",
        "y = torch.tensor(y_np)\n",
        "\n",
        "print(\"Datos preprocesados:\")\n",
        "print(f\"  X shape: {X.shape} (frases × features)\")\n",
        "print(f\"  y shape: {y.shape} (frases × 1)\")\n",
        "print(f\"\\nPrimera frase vectorizada: {X[0]}\")\n",
        "print(f\"Etiqueta: {y[0].item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-9",
      "metadata": {
        "id": "cell-9"
      },
      "source": [
        "## 5. Definición del modelo MLP\n",
        "\n",
        "Vamos a crear un modelo simple con:\n",
        "- **Capa de entrada**: Tamaño = cantidad de palabras en el vocabulario\n",
        "- **Capa oculta**: 8 neuronas con activación ReLU\n",
        "- **Capa de salida**: 1 neurona con activación Sigmoid (para clasificación binaria)\n",
        "\n",
        "### ¿Por qué estas activaciones?\n",
        "\n",
        "- **ReLU** (Rectified Linear Unit): `f(x) = max(0, x)` → Introduce no linealidad, permite aprender patrones complejos\n",
        "- **Sigmoid**: `f(x) = 1 / (1 + e^(-x))` → Convierte la salida a un valor entre 0 y 1 (probabilidad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-10",
        "outputId": "fd07302c-be02-4125-8eb2-285a115f2fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquitectura del modelo:\n",
            "MLP(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=8, out_features=1, bias=True)\n",
            "    (3): Sigmoid()\n",
            "  )\n",
            ")\n",
            "\n",
            "Parámetros totales: 145\n"
          ]
        }
      ],
      "source": [
        "input_size = len(vocabulario)\n",
        "hidden_size = 8\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        # Definimos la arquitectura secuencial\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),  # Capa oculta\n",
        "            nn.ReLU(),                            # Activación no lineal\n",
        "            nn.Linear(hidden_size, 1),            # Capa de salida\n",
        "            nn.Sigmoid()                          # Activación para clasificación binaria\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Propagación hacia adelante (forward pass)\"\"\"\n",
        "        return self.net(x)\n",
        "\n",
        "# Creamos una instancia del modelo\n",
        "modelo = MLP()\n",
        "\n",
        "print(\"Arquitectura del modelo:\")\n",
        "print(modelo)\n",
        "print(f\"\\nParámetros totales: {sum(p.numel() for p in modelo.parameters())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-11",
      "metadata": {
        "id": "cell-11"
      },
      "source": [
        "## 6. Configuración del entrenamiento\n",
        "\n",
        "Necesitamos definir dos componentes clave:\n",
        "\n",
        "### Función de pérdida (Loss Function)\n",
        "\n",
        "Usamos **Binary Cross Entropy (BCE)**: mide qué tan diferentes son las predicciones del modelo de las etiquetas reales. El objetivo del entrenamiento es minimizar esta pérdida.\n",
        "\n",
        "Fórmula: `BCE = -[y·log(ŷ) + (1-y)·log(1-ŷ)]`\n",
        "\n",
        "### Optimizador\n",
        "\n",
        "Usamos **Adam**: un optimizador moderno que ajusta automáticamente la tasa de aprendizaje para cada parámetro. Es más eficiente que el ajuste manual que hicimos en el perceptrón."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-12",
        "outputId": "31b38e71-2bd0-4288-cb81-f7195155fbf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuración de entrenamiento:\n",
            "  Loss function: Binary Cross Entropy\n",
            "  Optimizador: Adam\n",
            "  Learning rate: 0.01\n"
          ]
        }
      ],
      "source": [
        "# Función de pérdida\n",
        "criterio = nn.BCELoss()  # Binary Cross Entropy Loss\n",
        "\n",
        "# Optimizador\n",
        "optimizador = optim.Adam(modelo.parameters(), lr=0.01)\n",
        "\n",
        "print(\"Configuración de entrenamiento:\")\n",
        "print(f\"  Loss function: Binary Cross Entropy\")\n",
        "print(f\"  Optimizador: Adam\")\n",
        "print(f\"  Learning rate: 0.01\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-13",
      "metadata": {
        "id": "cell-13"
      },
      "source": [
        "## 7. Entrenamiento del modelo\n",
        "\n",
        "Vamos a entrenar el modelo por varias épocas. En cada época:\n",
        "1. Calculamos las predicciones (forward pass)\n",
        "2. Calculamos la pérdida\n",
        "3. Calculamos los gradientes (backpropagation)\n",
        "4. Actualizamos los pesos (optimizer step)\n",
        "\n",
        "Este proceso es automático gracias a PyTorch, a diferencia del ajuste manual que hicimos en el perceptrón."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-14",
        "outputId": "f407dad7-f113-481c-e2a8-501838bdf1ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "INICIANDO ENTRENAMIENTO\n",
            "============================================================\n",
            "Épocas: 50\n",
            "\n",
            "Época  10, Pérdida: 0.0073\n",
            "Época  20, Pérdida: 0.0066\n",
            "Época  30, Pérdida: 0.0060\n",
            "Época  40, Pérdida: 0.0055\n",
            "Época  50, Pérdida: 0.0050\n",
            "\n",
            "============================================================\n",
            "ENTRENAMIENTO FINALIZADO\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "epocas = 50\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"INICIANDO ENTRENAMIENTO\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Épocas: {epocas}\\n\")\n",
        "\n",
        "for epoca in range(epocas):\n",
        "    # Modo entrenamiento\n",
        "    modelo.train()\n",
        "\n",
        "    # Forward pass: calculamos predicciones\n",
        "    salida = modelo(X)\n",
        "\n",
        "    # Calculamos la pérdida\n",
        "    loss = criterio(salida, y)\n",
        "\n",
        "    # Backpropagation: calculamos gradientes\n",
        "    optimizador.zero_grad()  # Limpiamos gradientes previos\n",
        "    loss.backward()           # Calculamos nuevos gradientes\n",
        "\n",
        "    # Actualizamos pesos\n",
        "    optimizador.step()\n",
        "\n",
        "    # Mostramos progreso cada 10 épocas\n",
        "    if (epoca + 1) % 10 == 0:\n",
        "        print(f\"Época {epoca+1:3d}, Pérdida: {loss.item():.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ENTRENAMIENTO FINALIZADO\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-15",
      "metadata": {
        "id": "cell-15"
      },
      "source": [
        "## 8. Análisis del entrenamiento\n",
        "\n",
        "Observá cómo la pérdida disminuye con el tiempo. Esto indica que el modelo está aprendiendo a clasificar mejor las frases.\n",
        "\n",
        "Una pérdida cercana a 0 significa que el modelo está muy confiado en sus predicciones correctas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {
        "id": "cell-16"
      },
      "source": [
        "## 9. Evaluación con frases nuevas\n",
        "\n",
        "Probamos la red con frases que no estaban en el entrenamiento, para ver cómo generaliza."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-17",
        "outputId": "cc75327c-d156-4530-bd0c-1c82e12a0ef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "EVALUACIÓN EN FRASES NUEVAS\n",
            "============================================================\n",
            "\n",
            "Frase 1: 'No me gustó la atención, bastante mala'\n",
            "  Predicción: Negativo (probabilidad: 0.00)\n",
            "  Confianza: Alta\n",
            "\n",
            "Frase 2: 'Muy buena experiencia, todo excelente'\n",
            "  Predicción: Positivo (probabilidad: 0.97)\n",
            "  Confianza: Alta\n",
            "\n",
            "Frase 3: 'Una estafa total, no lo recomiendo'\n",
            "  Predicción: Positivo (probabilidad: 0.99)\n",
            "  Confianza: Alta\n",
            "\n",
            "Frase 4: 'Súper conforme con el servicio'\n",
            "  Predicción: Positivo (probabilidad: 1.00)\n",
            "  Confianza: Alta\n",
            "\n",
            "Frase 5: 'Nada que ver con lo prometido, una decepción'\n",
            "  Predicción: Positivo (probabilidad: 0.98)\n",
            "  Confianza: Alta\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "frases_prueba = [\n",
        "    \"No me gustó la atención, bastante mala\",\n",
        "    \"Muy buena experiencia, todo excelente\",\n",
        "    \"Una estafa total, no lo recomiendo\",\n",
        "    \"Súper conforme con el servicio\",\n",
        "    \"Nada que ver con lo prometido, una decepción\"\n",
        "]\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"EVALUACIÓN EN FRASES NUEVAS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Vectorizamos las frases de prueba\n",
        "X_prueba_np = np.array([vectorizar(frase, vocabulario) for frase in frases_prueba], dtype=np.float32)\n",
        "X_prueba = torch.tensor(X_prueba_np)\n",
        "\n",
        "# Modo evaluación (desactiva dropout, batch norm, etc.)\n",
        "modelo.eval()\n",
        "\n",
        "# Predicción sin calcular gradientes (más eficiente)\n",
        "with torch.no_grad():\n",
        "    predicciones = modelo(X_prueba)\n",
        "\n",
        "# Mostrar resultados\n",
        "for i, (frase, pred) in enumerate(zip(frases_prueba, predicciones), 1):\n",
        "    probabilidad = pred.item()\n",
        "    clase = \"Positivo\" if probabilidad >= 0.5 else \"Negativo\"\n",
        "    print(f\"\\nFrase {i}: '{frase}'\")\n",
        "    print(f\"  Predicción: {clase} (probabilidad: {probabilidad:.2f})\")\n",
        "\n",
        "    # Indicador visual de confianza\n",
        "    if probabilidad >= 0.8 or probabilidad <= 0.2:\n",
        "        print(f\"  Confianza: Alta\")\n",
        "    elif probabilidad >= 0.6 or probabilidad <= 0.4:\n",
        "        print(f\"  Confianza: Media\")\n",
        "    else:\n",
        "        print(f\"  Confianza: Baja (ambiguo)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-18",
      "metadata": {
        "id": "cell-18"
      },
      "source": [
        "## 10. Reflexión final\n",
        "\n",
        "### ¿Qué aprendimos?\n",
        "\n",
        "1. **Arquitectura multicapa**: Vimos cómo una red con capas ocultas puede aprender representaciones más complejas que un perceptrón simple.\n",
        "\n",
        "2. **Activaciones no lineales**: ReLU permite que la red aprenda patrones no lineales, algo imposible con un perceptrón simple.\n",
        "\n",
        "3. **Entrenamiento automático**: PyTorch maneja automáticamente el cálculo de gradientes (backpropagation) y la actualización de pesos, a diferencia del ajuste manual del perceptrón.\n",
        "\n",
        "4. **Probabilidades vs decisiones binarias**: La salida Sigmoid nos da una probabilidad (0-1) en lugar de solo 0 o 1, lo que permite medir la confianza del modelo.\n",
        "\n",
        "### Ventajas sobre el perceptrón simple\n",
        "\n",
        "- Puede aprender patrones más complejos (no lineales)\n",
        "- Mejor capacidad de generalización\n",
        "- Optimización más eficiente con Adam\n",
        "- Salida probabilística (más informativa)\n",
        "\n",
        "### Limitaciones que aún persisten\n",
        "\n",
        "1. **No considera el orden de las palabras**: Bag-of-words sigue sin capturar secuencias\n",
        "2. **Vocabulario fijo**: Solo conoce palabras predefinidas\n",
        "3. **Sin contexto global**: Cada palabra se procesa independientemente\n",
        "4. **Dataset pequeño**: Con solo 10 ejemplos, la generalización es limitada\n",
        "\n",
        "### ¿Qué sigue?\n",
        "\n",
        "En la próxima actividad vamos a ver cómo las **redes recurrentes (LSTM)** pueden procesar secuencias de palabras manteniendo memoria del contexto. Esto nos va a permitir:\n",
        "\n",
        "- Capturar el orden de las palabras\n",
        "- Entender dependencias temporales\n",
        "- Procesar frases de longitud variable\n",
        "- Aprovechar embeddings de palabras\n",
        "\n",
        "Las LSTM son el paso previo a entender los Transformers, que revolucionaron el NLP."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}