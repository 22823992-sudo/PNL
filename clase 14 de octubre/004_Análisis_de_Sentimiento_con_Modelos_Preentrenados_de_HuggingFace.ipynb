{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {
        "id": "cell-0"
      },
      "source": [
        "# Análisis de Sentimiento con Modelos Preentrenados de HuggingFace\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "En esta actividad vamos a utilizar un modelo de estado del arte ya entrenado para analizar el sentimiento de frases en español con apenas unas líneas de código, gracias a la librería HuggingFace Transformers.\n",
        "\n",
        "Vamos a mostrar cómo es posible aprovechar el poder de los Transformers como BERT sin necesidad de entrenar redes neuronales desde cero.\n",
        "\n",
        "### ¿Por qué esto es revolucionario?\n",
        "\n",
        "Hasta ahora entrenamos modelos desde cero:\n",
        "- Perceptrón con 6 ejemplos\n",
        "- MLP con 10 ejemplos\n",
        "- LSTM con 10 ejemplos\n",
        "\n",
        "**El problema**: Con tan pocos datos, los modelos aprenden poco y generalizan mal.\n",
        "\n",
        "**La solución**: Usar modelos que ya fueron entrenados con millones de textos. Esto se llama **transfer learning** (aprendizaje por transferencia)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-1",
      "metadata": {
        "id": "cell-1"
      },
      "source": [
        "## 1. Instalación de la librería transformers\n",
        "\n",
        "Si estás en Google Colab, instalá la librería con el siguiente comando:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-2",
      "metadata": {
        "id": "cell-2"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {
        "id": "cell-3"
      },
      "source": [
        "## 2. ¿Qué es BETO?\n",
        "\n",
        "Antes de usar el modelo, entendamos qué estamos cargando.\n",
        "\n",
        "### BETO = BERT en Español\n",
        "\n",
        "**BERT** (Bidirectional Encoder Representations from Transformers) es una arquitectura de modelo de lenguaje desarrollada por Google en 2018 que revolucionó el NLP.\n",
        "\n",
        "**BETO** es la versión en español de BERT, entrenada específicamente con textos en español.\n",
        "\n",
        "### Características de BETO:\n",
        "\n",
        "- **Entrenado con**: Wikipedia en español (millones de artículos)\n",
        "- **Arquitectura**: Transformer con atención bidireccional\n",
        "- **Parámetros**: ~110 millones\n",
        "- **Tiempo de entrenamiento**: Días en múltiples GPUs\n",
        "- **Costo de entrenamiento**: Miles de dólares en recursos computacionales\n",
        "\n",
        "### ¿Qué significa \"preentrenado\"?\n",
        "\n",
        "BETO ya aprendió:\n",
        "- Gramática del español\n",
        "- Vocabulario extenso\n",
        "- Relaciones semánticas entre palabras\n",
        "- Contextos en los que aparecen las palabras\n",
        "\n",
        "Nosotros vamos a usar ese conocimiento para análisis de sentimiento, sin tener que entrenar nada desde cero."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-4",
      "metadata": {
        "id": "cell-4"
      },
      "source": [
        "## 3. Cargando el modelo de análisis de sentimiento\n",
        "\n",
        "Vamos a usar `finiteautomata/beto-sentiment-analysis`, que es BETO ya ajustado específicamente para clasificar sentimientos en español.\n",
        "\n",
        "### ¿Qué es un pipeline?\n",
        "\n",
        "Un **pipeline** en HuggingFace encapsula todo el proceso:\n",
        "1. Tokenización del texto\n",
        "2. Conversión a formato del modelo\n",
        "3. Inferencia (predicción)\n",
        "4. Post-procesamiento de resultados\n",
        "\n",
        "Todo esto en una sola línea de código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {
        "id": "cell-5"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "print(\"Cargando modelo BETO para análisis de sentimiento...\")\n",
        "print(\"Este proceso descarga el modelo (puede tardar unos segundos la primera vez)\\n\")\n",
        "\n",
        "# Cargamos el pipeline de análisis de sentimientos con el modelo en español\n",
        "clasificador = pipeline(\"sentiment-analysis\", model=\"finiteautomata/beto-sentiment-analysis\")\n",
        "\n",
        "print(\"Modelo cargado exitosamente\")\n",
        "print(f\"Modelo: {clasificador.model.config._name_or_path}\")\n",
        "print(f\"\\nEste modelo fue ajustado (fine-tuned) específicamente para español.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-6",
      "metadata": {
        "id": "cell-6"
      },
      "source": [
        "## 4. Comparación con nuestros modelos anteriores\n",
        "\n",
        "Antes de probar BETO, recordemos las limitaciones de nuestros modelos:\n",
        "\n",
        "| Aspecto | Nuestros modelos | BETO |\n",
        "|---------|-----------------|------|\n",
        "| Datos de entrenamiento | 6-10 frases | Millones de textos |\n",
        "| Vocabulario | 10-50 palabras | ~30,000 tokens |\n",
        "| Parámetros | Cientos/Miles | 110 millones |\n",
        "| Tiempo de entrenamiento | Segundos | Días en GPUs |\n",
        "| Comprensión del lenguaje | Básica | Avanzada |\n",
        "\n",
        "Esta diferencia de escala es lo que hace que BETO sea tan poderoso."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-7",
      "metadata": {
        "id": "cell-7"
      },
      "source": [
        "## 5. Evaluación de frases variadas\n",
        "\n",
        "Ahora vamos a probar el modelo con frases reales, incluyendo expresiones típicas de Argentina."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-8",
      "metadata": {
        "id": "cell-8"
      },
      "outputs": [],
      "source": [
        "frases = [\n",
        "    \"Este lugar es espectacular, lo recomiendo totalmente\",\n",
        "    \"Una decepción total. No pienso volver\",\n",
        "    \"Más o menos... esperaba otra cosa\",\n",
        "    \"Qué buena onda la atención, me encantó\",\n",
        "    \"Mala calidad, pésimo servicio\",\n",
        "    \"Zafa, pero nada especial\",\n",
        "    \"Me sentí muy bien atendido\",\n",
        "    \"Una estafa. Me arrepiento totalmente\",\n",
        "    \"Todo excelente, 10 puntos\",\n",
        "    \"Nunca más. Fue un desastre\"\n",
        "]\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"PREDICCIONES DE BETO EN FRASES VARIADAS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Clasificamos cada frase\n",
        "resultados = clasificador(frases)\n",
        "\n",
        "# Mostramos los resultados\n",
        "for i, (frase, resultado) in enumerate(zip(frases, resultados), 1):\n",
        "    sentimiento = resultado['label']\n",
        "    confianza = resultado['score']\n",
        "\n",
        "    print(f\"\\nFrase {i}: '{frase}'\")\n",
        "    print(f\"  Predicción: {sentimiento} (confianza: {confianza:.2f})\")\n",
        "\n",
        "    # Indicador de confianza\n",
        "    if confianza >= 0.9:\n",
        "        print(f\"  Confianza: Muy alta\")\n",
        "    elif confianza >= 0.7:\n",
        "        print(f\"  Confianza: Alta\")\n",
        "    elif confianza >= 0.5:\n",
        "        print(f\"  Confianza: Media\")\n",
        "    else:\n",
        "        print(f\"  Confianza: Baja (poco seguro)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-9",
      "metadata": {
        "id": "cell-9"
      },
      "source": [
        "## 6. Análisis de expresiones rioplatenses\n",
        "\n",
        "Vamos a probar específicamente con expresiones típicas de Argentina para ver si BETO las entiende."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-10",
      "metadata": {
        "id": "cell-10"
      },
      "outputs": [],
      "source": [
        "expresiones_argentinas = [\n",
        "    \"Está re copado este lugar\",\n",
        "    \"Qué garrón, me clavaron\",\n",
        "    \"La pasé bomba, volvería sin dudarlo\",\n",
        "    \"Un bodrio total, no lo banco más\",\n",
        "    \"Me re sirvió, gracias\",\n",
        "    \"Qué embole, fue un bajón\"\n",
        "]\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"BETO CON EXPRESIONES RIOPLATENSES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "resultados = clasificador(expresiones_argentinas)\n",
        "\n",
        "for frase, resultado in zip(expresiones_argentinas, resultados):\n",
        "    print(f\"\\nFrase: '{frase}'\")\n",
        "    print(f\"  {resultado['label']} ({resultado['score']:.2f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Observá cómo BETO entiende modismos argentinos como:\")\n",
        "print(\"  'copado', 'garrón', 'bomba', 'bodrio', 'embole', 'bajón'\")\n",
        "print(\"Esto es gracias a su entrenamiento con textos en español variados.\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-11",
      "metadata": {
        "id": "cell-11"
      },
      "source": [
        "## 7. Casos desafiantes: Opiniones mixtas y matices\n",
        "\n",
        "Probemos con casos más complejos que suelen confundir a modelos simples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-12",
      "metadata": {
        "id": "cell-12"
      },
      "outputs": [],
      "source": [
        "casos_complejos = [\n",
        "    \"La comida estuvo bien pero el servicio fue horrible\",\n",
        "    \"No estuvo mal, aunque esperaba más por el precio\",\n",
        "    \"Pensé que iba a ser un desastre pero me sorprendió para bien\",\n",
        "    \"Excelente producto, lástima la demora en el envío\",\n",
        "    \"No puedo decir que no me gustó, porque sería mentir\"\n",
        "]\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CASOS COMPLEJOS: OPINIONES MIXTAS Y MATICES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "resultados = clasificador(casos_complejos)\n",
        "\n",
        "for i, (frase, resultado) in enumerate(zip(casos_complejos, resultados), 1):\n",
        "    print(f\"\\nCaso {i}: '{frase}'\")\n",
        "    print(f\"  Predicción: {resultado['label']} (confianza: {resultado['score']:.2f})\")\n",
        "\n",
        "    # Análisis del caso\n",
        "    if i == 1:\n",
        "        print(f\"  Análisis: Opinión mixta (comida bien, servicio mal)\")\n",
        "    elif i == 2:\n",
        "        print(f\"  Análisis: Sentimiento tibio con matices\")\n",
        "    elif i == 3:\n",
        "        print(f\"  Análisis: Giro de expectativa negativa a positiva\")\n",
        "    elif i == 4:\n",
        "        print(f\"  Análisis: Positivo con salvedad\")\n",
        "    elif i == 5:\n",
        "        print(f\"  Análisis: Doble negación (no... no = sí)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-13",
      "metadata": {
        "id": "cell-13"
      },
      "source": [
        "## 8. Comparación directa: ¿Cómo se compara con LSTM?\n",
        "\n",
        "Recordemos que con LSTM entrenamos con 10 frases. BETO, en cambio, fue entrenado con millones de textos.\n",
        "\n",
        "### Ventajas observadas de BETO:\n",
        "\n",
        "1. **Vocabulario extenso**: Entiende palabras que nunca vio en nuestro pequeño dataset\n",
        "2. **Contexto bidireccional**: Mira toda la frase simultáneamente, no solo de izquierda a derecha\n",
        "3. **Modismos y expresiones**: Reconoce jerga argentina sin entrenamiento específico\n",
        "4. **Matices**: Maneja mejor opiniones mixtas y giros en el sentimiento\n",
        "5. **Confianza calibrada**: Los scores reflejan mejor la certeza del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-14",
      "metadata": {
        "id": "cell-14"
      },
      "source": [
        "## 9. Probá tus propias frases\n",
        "\n",
        "Ahora te toca experimentar. Agregá frases propias y observá cómo se comporta BETO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-15",
      "metadata": {
        "id": "cell-15"
      },
      "outputs": [],
      "source": [
        "# Agregá tus propias frases acá\n",
        "mis_frases = [\n",
        "    \"Tu frase 1\",\n",
        "    \"Tu frase 2\",\n",
        "    \"Tu frase 3\"\n",
        "]\n",
        "\n",
        "# Descomentá estas líneas cuando tengas tus frases\n",
        "# resultados_propios = clasificador(mis_frases)\n",
        "# for frase, resultado in zip(mis_frases, resultados_propios):\n",
        "#     print(f\"\\nFrase: '{frase}'\")\n",
        "#     print(f\"  Predicción: {resultado['label']} ({resultado['score']:.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {
        "id": "cell-16"
      },
      "source": [
        "## 10. Reflexión final\n",
        "\n",
        "### ¿Qué aprendimos?\n",
        "\n",
        "1. **Transfer learning es poderoso**: No necesitamos entrenar desde cero para obtener buenos resultados en NLP.\n",
        "\n",
        "2. **Modelos preentrenados en español**: Existen modelos como BETO que entienden texto coloquial, incluso modismos regionales.\n",
        "\n",
        "3. **Facilidad de uso**: Con HuggingFace Transformers podemos usar modelos de estado del arte con apenas unas líneas de código.\n",
        "\n",
        "4. **Escala importa**: Un modelo entrenado con millones de ejemplos es cualitativamente diferente a uno entrenado con 10.\n",
        "\n",
        "### Comparación con nuestros modelos anteriores:\n",
        "\n",
        "**Perceptrón (Lab 1)**:\n",
        "- Entrenamiento: 6 frases, segundos\n",
        "- Limitación: Modelo lineal, bag-of-words\n",
        "- Resultado: Clasificación básica\n",
        "\n",
        "**MLP (Lab 2)**:\n",
        "- Entrenamiento: 10 frases, segundos\n",
        "- Mejora: Patrones no lineales\n",
        "- Limitación: Sigue sin orden, bag-of-words\n",
        "\n",
        "**LSTM (Lab 3)**:\n",
        "- Entrenamiento: 10 frases, minutos\n",
        "- Mejora: Procesa secuencias, embeddings\n",
        "- Limitación: Dataset pequeño, vocabulario limitado\n",
        "\n",
        "**BETO (Lab 4)**:\n",
        "- Entrenamiento: Millones de textos, días en GPUs\n",
        "- Mejora: Comprensión profunda del español\n",
        "- Uso: Sin entrenar, solo inferencia\n",
        "\n",
        "### ¿Por qué esto cambió el NLP?\n",
        "\n",
        "Antes de 2018 (pre-BERT), cada tarea requería:\n",
        "1. Conseguir dataset grande específico\n",
        "2. Entrenar modelo desde cero\n",
        "3. Esperar que generalizara\n",
        "\n",
        "Después de 2018 (era Transformer):\n",
        "1. Usar modelo preentrenado\n",
        "2. Opcionalmente: ajustar con pocos ejemplos (fine-tuning)\n",
        "3. Obtener resultados superiores\n",
        "\n",
        "### Conceptos clave para entender LLMs:\n",
        "\n",
        "Lo que vimos hoy es la base de cómo funcionan los LLMs modernos:\n",
        "\n",
        "- **Preentrenamiento masivo**: GPT, BERT, LLaMA se entrenan con billones de palabras\n",
        "- **Arquitectura Transformer**: Atención en lugar de procesamiento secuencial\n",
        "- **Transfer learning**: El conocimiento se transfiere entre tareas\n",
        "- **Emergencia de capacidades**: Con suficiente escala, surgen habilidades no programadas explícitamente\n",
        "\n",
        "### ¿Qué sigue?\n",
        "\n",
        "En las próximas clases vamos a profundizar en:\n",
        "- Arquitectura Transformer en detalle\n",
        "- Mecanismo de atención\n",
        "- Cómo se entrenan modelos como GPT\n",
        "- Fine-tuning y prompting\n",
        "- Construcción de aplicaciones con LLMs\n",
        "\n",
        "Hoy vimos **qué** pueden hacer estos modelos. Próximamente veremos **cómo** funcionan por dentro."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}